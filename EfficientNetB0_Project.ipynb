{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB0_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIXAUB68qNsJy5w1+iaJjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayazzazay/MRP/blob/main/EfficientNetB0_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvvPjLYxrvV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1badcf-9423-4773-bacb-fed8cab0ee45"
      },
      "source": [
        "# to upload the dataset folder to colab from google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRHEW3JbrxHL"
      },
      "source": [
        "# importing libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.utils import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjofawesrxJm"
      },
      "source": [
        "# getting the paths of train and test data\n",
        "\n",
        "train_40x_path = '/content/drive/MyDrive/breast_cancer_data/train_40x'\n",
        "test_40x_path = '/content/drive/MyDrive/breast_cancer_data/test_40x'\n",
        "valid_40x_path = '/content/drive/MyDrive/breast_cancer_data/valid_40x'\n",
        "\n",
        "train_100x_path = '/content/drive/MyDrive/breast_cancer_data/train_100x'\n",
        "test_100x_path = '/content/drive/MyDrive/breast_cancer_data/test_100x'\n",
        "valid_100x_path = '/content/drive/MyDrive/breast_cancer_data/valid_100x'\n",
        "\n",
        "train_200x_path = '/content/drive/MyDrive/breast_cancer_data/train_200x'\n",
        "test_200x_path = '/content/drive/MyDrive/breast_cancer_data/test_200x'\n",
        "valid_200x_path = '/content/drive/MyDrive/breast_cancer_data/valid_200x'\n",
        "\n",
        "train_400x_path = '/content/drive/MyDrive/breast_cancer_data/train_400x'\n",
        "test_400x_path = '/content/drive/MyDrive/breast_cancer_data/test_400x'\n",
        "valid_400x_path = '/content/drive/MyDrive/breast_cancer_data/valid_400x'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA5bt7wtrxMj"
      },
      "source": [
        "n_epochs = 80\n",
        "height = 224\n",
        "width = 224\n",
        "channels = 3\n",
        "input_shape = (height, width, channels)\n",
        "n_classes = 2\n",
        "lr = 1e-3\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J1iyqOOrxPC"
      },
      "source": [
        "datagen = ImageDataGenerator( horizontal_flip = True, rotation_range=40, fill_mode = 'reflect', width_shift_range = 0.2, height_shift_range = 0.2, vertical_flip=True, preprocessing_function = preprocess_input)\n",
        "datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4AaZDvir8Jb"
      },
      "source": [
        "### 40x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j96fbrWDrxRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534ca8c5-9ec8-4681-fb3e-4300981fd8d6"
      },
      "source": [
        "train_generator_40x = datagen.flow_from_directory( train_40x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_40x = datagen_test.flow_from_directory( valid_40x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_40x = datagen_test.flow_from_directory( test_40x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1197 images belonging to 2 classes.\n",
            "Found 399 images belonging to 2 classes.\n",
            "Found 399 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJqqIvsrxUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94afdb1-24b3-4bc9-eb6e-173f2b7ebb57"
      },
      "source": [
        "efnb_40x = EfficientNetB0(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_40x = Sequential()\n",
        "model_40x.add(efnb_40x)\n",
        "model_40x.add(GlobalAveragePooling2D())\n",
        "model_40x.add(Dropout(0.2))\n",
        "model_40x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "efnb_40x.trainable = False\n",
        "\n",
        "model_40x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "hist_40x = model_40x.fit(train_generator_40x, validation_data = valid_generator_40x, epochs = n_epochs, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Epoch 1/80\n",
            "75/75 [==============================] - 700s 9s/step - loss: 0.4767 - acc: 0.7719 - val_loss: 0.3340 - val_acc: 0.8922\n",
            "Epoch 2/80\n",
            "75/75 [==============================] - 34s 461ms/step - loss: 0.3964 - acc: 0.8354 - val_loss: 0.2993 - val_acc: 0.8922\n",
            "Epoch 3/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.3399 - acc: 0.8663 - val_loss: 0.2822 - val_acc: 0.9023\n",
            "Epoch 4/80\n",
            "75/75 [==============================] - 35s 461ms/step - loss: 0.3371 - acc: 0.8705 - val_loss: 0.2464 - val_acc: 0.9148\n",
            "Epoch 5/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.3139 - acc: 0.8713 - val_loss: 0.2390 - val_acc: 0.9173\n",
            "Epoch 6/80\n",
            "75/75 [==============================] - 34s 457ms/step - loss: 0.3085 - acc: 0.8705 - val_loss: 0.2310 - val_acc: 0.9223\n",
            "Epoch 7/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2962 - acc: 0.8797 - val_loss: 0.2194 - val_acc: 0.9298\n",
            "Epoch 8/80\n",
            "75/75 [==============================] - 34s 456ms/step - loss: 0.2940 - acc: 0.8797 - val_loss: 0.2134 - val_acc: 0.9323\n",
            "Epoch 9/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2812 - acc: 0.8847 - val_loss: 0.2180 - val_acc: 0.9248\n",
            "Epoch 10/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2820 - acc: 0.8897 - val_loss: 0.2033 - val_acc: 0.9323\n",
            "Epoch 11/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2651 - acc: 0.8939 - val_loss: 0.1953 - val_acc: 0.9348\n",
            "Epoch 12/80\n",
            "75/75 [==============================] - 34s 457ms/step - loss: 0.2607 - acc: 0.8972 - val_loss: 0.1889 - val_acc: 0.9424\n",
            "Epoch 13/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2530 - acc: 0.9014 - val_loss: 0.1955 - val_acc: 0.9373\n",
            "Epoch 14/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.2533 - acc: 0.8972 - val_loss: 0.1759 - val_acc: 0.9398\n",
            "Epoch 15/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2410 - acc: 0.9048 - val_loss: 0.1965 - val_acc: 0.9348\n",
            "Epoch 16/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.2484 - acc: 0.9073 - val_loss: 0.1801 - val_acc: 0.9449\n",
            "Epoch 17/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2476 - acc: 0.9006 - val_loss: 0.1846 - val_acc: 0.9424\n",
            "Epoch 18/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2407 - acc: 0.9081 - val_loss: 0.1919 - val_acc: 0.9348\n",
            "Epoch 19/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2308 - acc: 0.9106 - val_loss: 0.1684 - val_acc: 0.9499\n",
            "Epoch 20/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2288 - acc: 0.9106 - val_loss: 0.1561 - val_acc: 0.9398\n",
            "Epoch 21/80\n",
            "75/75 [==============================] - 35s 462ms/step - loss: 0.2379 - acc: 0.9048 - val_loss: 0.1609 - val_acc: 0.9499\n",
            "Epoch 22/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.2275 - acc: 0.9023 - val_loss: 0.1541 - val_acc: 0.9499\n",
            "Epoch 23/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2227 - acc: 0.9165 - val_loss: 0.1562 - val_acc: 0.9449\n",
            "Epoch 24/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2285 - acc: 0.9089 - val_loss: 0.1593 - val_acc: 0.9348\n",
            "Epoch 25/80\n",
            "75/75 [==============================] - 35s 460ms/step - loss: 0.2348 - acc: 0.9056 - val_loss: 0.1517 - val_acc: 0.9524\n",
            "Epoch 26/80\n",
            "75/75 [==============================] - 35s 471ms/step - loss: 0.2283 - acc: 0.9098 - val_loss: 0.1480 - val_acc: 0.9449\n",
            "Epoch 27/80\n",
            "75/75 [==============================] - 35s 471ms/step - loss: 0.2171 - acc: 0.9123 - val_loss: 0.1505 - val_acc: 0.9499\n",
            "Epoch 28/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2048 - acc: 0.9240 - val_loss: 0.1440 - val_acc: 0.9524\n",
            "Epoch 29/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2129 - acc: 0.9114 - val_loss: 0.1507 - val_acc: 0.9499\n",
            "Epoch 30/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2185 - acc: 0.9215 - val_loss: 0.1417 - val_acc: 0.9424\n",
            "Epoch 31/80\n",
            "75/75 [==============================] - 35s 465ms/step - loss: 0.2087 - acc: 0.9198 - val_loss: 0.1421 - val_acc: 0.9449\n",
            "Epoch 32/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.1937 - acc: 0.9231 - val_loss: 0.1406 - val_acc: 0.9499\n",
            "Epoch 33/80\n",
            "75/75 [==============================] - 35s 464ms/step - loss: 0.2156 - acc: 0.9106 - val_loss: 0.1459 - val_acc: 0.9499\n",
            "Epoch 34/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2102 - acc: 0.9265 - val_loss: 0.1360 - val_acc: 0.9424\n",
            "Epoch 35/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2188 - acc: 0.9140 - val_loss: 0.1333 - val_acc: 0.9449\n",
            "Epoch 36/80\n",
            "75/75 [==============================] - 34s 461ms/step - loss: 0.2190 - acc: 0.9064 - val_loss: 0.1298 - val_acc: 0.9499\n",
            "Epoch 37/80\n",
            "75/75 [==============================] - 34s 455ms/step - loss: 0.1818 - acc: 0.9298 - val_loss: 0.1305 - val_acc: 0.9524\n",
            "Epoch 38/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2199 - acc: 0.9073 - val_loss: 0.1337 - val_acc: 0.9549\n",
            "Epoch 39/80\n",
            "75/75 [==============================] - 34s 457ms/step - loss: 0.2119 - acc: 0.9089 - val_loss: 0.1298 - val_acc: 0.9474\n",
            "Epoch 40/80\n",
            "75/75 [==============================] - 35s 461ms/step - loss: 0.2196 - acc: 0.9123 - val_loss: 0.1288 - val_acc: 0.9549\n",
            "Epoch 41/80\n",
            "75/75 [==============================] - 34s 457ms/step - loss: 0.1924 - acc: 0.9231 - val_loss: 0.1301 - val_acc: 0.9549\n",
            "Epoch 42/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2093 - acc: 0.9190 - val_loss: 0.1371 - val_acc: 0.9599\n",
            "Epoch 43/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2054 - acc: 0.9223 - val_loss: 0.1323 - val_acc: 0.9524\n",
            "Epoch 44/80\n",
            "75/75 [==============================] - 34s 457ms/step - loss: 0.1953 - acc: 0.9240 - val_loss: 0.1259 - val_acc: 0.9574\n",
            "Epoch 45/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.1866 - acc: 0.9240 - val_loss: 0.1267 - val_acc: 0.9549\n",
            "Epoch 46/80\n",
            "75/75 [==============================] - 34s 455ms/step - loss: 0.1964 - acc: 0.9198 - val_loss: 0.1369 - val_acc: 0.9574\n",
            "Epoch 47/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2095 - acc: 0.9265 - val_loss: 0.1303 - val_acc: 0.9649\n",
            "Epoch 48/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2042 - acc: 0.9173 - val_loss: 0.1292 - val_acc: 0.9599\n",
            "Epoch 49/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2035 - acc: 0.9156 - val_loss: 0.1323 - val_acc: 0.9599\n",
            "Epoch 50/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2107 - acc: 0.9156 - val_loss: 0.1275 - val_acc: 0.9574\n",
            "Epoch 51/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.1997 - acc: 0.9165 - val_loss: 0.1340 - val_acc: 0.9549\n",
            "Epoch 52/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.1872 - acc: 0.9215 - val_loss: 0.1294 - val_acc: 0.9574\n",
            "Epoch 53/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2129 - acc: 0.9131 - val_loss: 0.1281 - val_acc: 0.9549\n",
            "Epoch 54/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.1829 - acc: 0.9348 - val_loss: 0.1295 - val_acc: 0.9524\n",
            "Epoch 55/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.1950 - acc: 0.9206 - val_loss: 0.1323 - val_acc: 0.9624\n",
            "Epoch 56/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.2059 - acc: 0.9173 - val_loss: 0.1314 - val_acc: 0.9549\n",
            "Epoch 57/80\n",
            "75/75 [==============================] - 35s 463ms/step - loss: 0.2066 - acc: 0.9181 - val_loss: 0.1298 - val_acc: 0.9649\n",
            "Epoch 58/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.1889 - acc: 0.9357 - val_loss: 0.1414 - val_acc: 0.9649\n",
            "Epoch 59/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.1889 - acc: 0.9298 - val_loss: 0.1252 - val_acc: 0.9624\n",
            "Epoch 60/80\n",
            "75/75 [==============================] - 34s 458ms/step - loss: 0.2001 - acc: 0.9256 - val_loss: 0.1240 - val_acc: 0.9499\n",
            "Epoch 61/80\n",
            "75/75 [==============================] - 34s 460ms/step - loss: 0.1833 - acc: 0.9273 - val_loss: 0.1222 - val_acc: 0.9624\n",
            "Epoch 62/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.1709 - acc: 0.9348 - val_loss: 0.1228 - val_acc: 0.9599\n",
            "Epoch 63/80\n",
            "75/75 [==============================] - 35s 463ms/step - loss: 0.1984 - acc: 0.9223 - val_loss: 0.1325 - val_acc: 0.9649\n",
            "Epoch 64/80\n",
            "75/75 [==============================] - 35s 462ms/step - loss: 0.1992 - acc: 0.9089 - val_loss: 0.1310 - val_acc: 0.9599\n",
            "Epoch 65/80\n",
            "75/75 [==============================] - 35s 462ms/step - loss: 0.1662 - acc: 0.9323 - val_loss: 0.1275 - val_acc: 0.9549\n",
            "Epoch 66/80\n",
            "75/75 [==============================] - 35s 465ms/step - loss: 0.2116 - acc: 0.9114 - val_loss: 0.1272 - val_acc: 0.9474\n",
            "Epoch 67/80\n",
            "75/75 [==============================] - 35s 463ms/step - loss: 0.1945 - acc: 0.9215 - val_loss: 0.1243 - val_acc: 0.9524\n",
            "Epoch 68/80\n",
            "75/75 [==============================] - 35s 465ms/step - loss: 0.1863 - acc: 0.9181 - val_loss: 0.1348 - val_acc: 0.9549\n",
            "Epoch 69/80\n",
            "75/75 [==============================] - 35s 463ms/step - loss: 0.1786 - acc: 0.9282 - val_loss: 0.1237 - val_acc: 0.9499\n",
            "Epoch 70/80\n",
            "75/75 [==============================] - 35s 463ms/step - loss: 0.1912 - acc: 0.9190 - val_loss: 0.1210 - val_acc: 0.9524\n",
            "Epoch 71/80\n",
            "75/75 [==============================] - 35s 461ms/step - loss: 0.1865 - acc: 0.9298 - val_loss: 0.1202 - val_acc: 0.9524\n",
            "Epoch 72/80\n",
            "75/75 [==============================] - 35s 461ms/step - loss: 0.1865 - acc: 0.9215 - val_loss: 0.1258 - val_acc: 0.9624\n",
            "Epoch 73/80\n",
            "75/75 [==============================] - 35s 465ms/step - loss: 0.1969 - acc: 0.9198 - val_loss: 0.1245 - val_acc: 0.9624\n",
            "Epoch 74/80\n",
            "75/75 [==============================] - 35s 463ms/step - loss: 0.1700 - acc: 0.9348 - val_loss: 0.1243 - val_acc: 0.9574\n",
            "Epoch 75/80\n",
            "75/75 [==============================] - 35s 461ms/step - loss: 0.1752 - acc: 0.9298 - val_loss: 0.1305 - val_acc: 0.9624\n",
            "Epoch 76/80\n",
            "75/75 [==============================] - 35s 465ms/step - loss: 0.1896 - acc: 0.9340 - val_loss: 0.1241 - val_acc: 0.9549\n",
            "Epoch 77/80\n",
            "75/75 [==============================] - 35s 467ms/step - loss: 0.1751 - acc: 0.9223 - val_loss: 0.1286 - val_acc: 0.9549\n",
            "Epoch 78/80\n",
            "75/75 [==============================] - 35s 466ms/step - loss: 0.1854 - acc: 0.9248 - val_loss: 0.1232 - val_acc: 0.9574\n",
            "Epoch 79/80\n",
            "75/75 [==============================] - 34s 459ms/step - loss: 0.1874 - acc: 0.9198 - val_loss: 0.1247 - val_acc: 0.9549\n",
            "Epoch 80/80\n",
            "75/75 [==============================] - 35s 463ms/step - loss: 0.1849 - acc: 0.9315 - val_loss: 0.1273 - val_acc: 0.9624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3xuwU0SrxZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e0c777-ef7d-451e-c7f3-4926cdf46d6a"
      },
      "source": [
        "y_test_40x = test_generator_40x.classes\n",
        "y_pred_40x = model_40x.predict(test_generator_40x, verbose = 1)\n",
        "y_pred_40x = np.argmax(y_pred_40x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_40x, y_pred_40x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_40x, y_pred_40x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_40x, y_pred_40x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_40x, y_pred_40x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 156s 6s/step\n",
            "The Accuracy on the testing data : 94.99%\n",
            "The F1 Score on the testing data : 96.38%\n",
            "The Precision on the testing data : 96.38%\n",
            "The Recall on the testing data : 96.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alF-FEQ3sUIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362d0cb4-a129-4b25-856a-f67c19046714"
      },
      "source": [
        "tn_40x, fp_40x, fn_40x, tp_40x = confusion_matrix(y_test_40x, y_pred_40x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_40x)\n",
        "print('True Negitive : ',tn_40x)\n",
        "print('False Positive : ',fp_40x)\n",
        "print('False Negitive : ',fn_40x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  266\n",
            "True Negitive :  113\n",
            "False Positive :  10\n",
            "False Negitive :  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "copdpDTTdRDp",
        "outputId": "853a1b2f-85b4-470a-95f0-f4369e043c20"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (266 / (266 + 10))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (113 / (113 + 10))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  96.38%\n",
            "Specificity :  91.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrS5ox0_sU_y"
      },
      "source": [
        "### 100x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htPMLPPosXwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e82961-fe35-4084-f671-3010898bbea9"
      },
      "source": [
        "train_generator_100x = datagen.flow_from_directory( train_100x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_100x = datagen_test.flow_from_directory( valid_100x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_100x = datagen_test.flow_from_directory( test_100x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1248 images belonging to 2 classes.\n",
            "Found 416 images belonging to 2 classes.\n",
            "Found 417 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOP3bG0etgws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3a4666-eab2-4c48-a50a-4daa76c6a602"
      },
      "source": [
        "efnb_100x = EfficientNetB0(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_100x = Sequential()\n",
        "model_100x.add(efnb_100x)\n",
        "model_100x.add(GlobalAveragePooling2D())\n",
        "model_100x.add(Dropout(0.2))\n",
        "model_100x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "efnb_100x.trainable = False\n",
        "\n",
        "model_100x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "\n",
        "hist_100x = model_100x.fit(train_generator_100x, validation_data = valid_generator_100x, epochs = n_epochs, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Epoch 1/80\n",
            "78/78 [==============================] - 697s 8s/step - loss: 0.4910 - acc: 0.7676 - val_loss: 0.3444 - val_acc: 0.8870\n",
            "Epoch 2/80\n",
            "78/78 [==============================] - 41s 525ms/step - loss: 0.4028 - acc: 0.8373 - val_loss: 0.3081 - val_acc: 0.8726\n",
            "Epoch 3/80\n",
            "78/78 [==============================] - 41s 526ms/step - loss: 0.3549 - acc: 0.8630 - val_loss: 0.2685 - val_acc: 0.8918\n",
            "Epoch 4/80\n",
            "78/78 [==============================] - 41s 525ms/step - loss: 0.3417 - acc: 0.8598 - val_loss: 0.2532 - val_acc: 0.9207\n",
            "Epoch 5/80\n",
            "78/78 [==============================] - 41s 526ms/step - loss: 0.3151 - acc: 0.8774 - val_loss: 0.2393 - val_acc: 0.9062\n",
            "Epoch 6/80\n",
            "78/78 [==============================] - 41s 523ms/step - loss: 0.3137 - acc: 0.8758 - val_loss: 0.2324 - val_acc: 0.9111\n",
            "Epoch 7/80\n",
            "78/78 [==============================] - 41s 523ms/step - loss: 0.2836 - acc: 0.8862 - val_loss: 0.2194 - val_acc: 0.9327\n",
            "Epoch 8/80\n",
            "78/78 [==============================] - 41s 522ms/step - loss: 0.2838 - acc: 0.8894 - val_loss: 0.2125 - val_acc: 0.9255\n",
            "Epoch 9/80\n",
            "78/78 [==============================] - 41s 523ms/step - loss: 0.2916 - acc: 0.8822 - val_loss: 0.2112 - val_acc: 0.9231\n",
            "Epoch 10/80\n",
            "78/78 [==============================] - 41s 525ms/step - loss: 0.2629 - acc: 0.8918 - val_loss: 0.2074 - val_acc: 0.9231\n",
            "Epoch 11/80\n",
            "78/78 [==============================] - 40s 518ms/step - loss: 0.2801 - acc: 0.8942 - val_loss: 0.2052 - val_acc: 0.9303\n",
            "Epoch 12/80\n",
            "78/78 [==============================] - 39s 499ms/step - loss: 0.2457 - acc: 0.9054 - val_loss: 0.1937 - val_acc: 0.9327\n",
            "Epoch 13/80\n",
            "78/78 [==============================] - 39s 497ms/step - loss: 0.2595 - acc: 0.8950 - val_loss: 0.1919 - val_acc: 0.9327\n",
            "Epoch 14/80\n",
            "78/78 [==============================] - 39s 498ms/step - loss: 0.2445 - acc: 0.9079 - val_loss: 0.1914 - val_acc: 0.9303\n",
            "Epoch 15/80\n",
            "78/78 [==============================] - 39s 498ms/step - loss: 0.2322 - acc: 0.9135 - val_loss: 0.1891 - val_acc: 0.9279\n",
            "Epoch 16/80\n",
            "78/78 [==============================] - 39s 498ms/step - loss: 0.2571 - acc: 0.9038 - val_loss: 0.1808 - val_acc: 0.9375\n",
            "Epoch 17/80\n",
            "78/78 [==============================] - 39s 500ms/step - loss: 0.2260 - acc: 0.9087 - val_loss: 0.1820 - val_acc: 0.9279\n",
            "Epoch 18/80\n",
            "78/78 [==============================] - 39s 499ms/step - loss: 0.2513 - acc: 0.8990 - val_loss: 0.2044 - val_acc: 0.9111\n",
            "Epoch 19/80\n",
            "78/78 [==============================] - 39s 506ms/step - loss: 0.2324 - acc: 0.9111 - val_loss: 0.1734 - val_acc: 0.9375\n",
            "Epoch 20/80\n",
            "78/78 [==============================] - 39s 504ms/step - loss: 0.2327 - acc: 0.9135 - val_loss: 0.1780 - val_acc: 0.9279\n",
            "Epoch 21/80\n",
            "78/78 [==============================] - 39s 496ms/step - loss: 0.2409 - acc: 0.9022 - val_loss: 0.1948 - val_acc: 0.9231\n",
            "Epoch 22/80\n",
            "78/78 [==============================] - 39s 496ms/step - loss: 0.2487 - acc: 0.8998 - val_loss: 0.1688 - val_acc: 0.9495\n",
            "Epoch 23/80\n",
            "78/78 [==============================] - 39s 497ms/step - loss: 0.2478 - acc: 0.9022 - val_loss: 0.1686 - val_acc: 0.9447\n",
            "Epoch 24/80\n",
            "78/78 [==============================] - 39s 497ms/step - loss: 0.2255 - acc: 0.9127 - val_loss: 0.1674 - val_acc: 0.9423\n",
            "Epoch 25/80\n",
            "78/78 [==============================] - 39s 496ms/step - loss: 0.2247 - acc: 0.9135 - val_loss: 0.1621 - val_acc: 0.9447\n",
            "Epoch 26/80\n",
            "78/78 [==============================] - 39s 495ms/step - loss: 0.2294 - acc: 0.9159 - val_loss: 0.1592 - val_acc: 0.9423\n",
            "Epoch 27/80\n",
            "78/78 [==============================] - 40s 508ms/step - loss: 0.2287 - acc: 0.9062 - val_loss: 0.1602 - val_acc: 0.9519\n",
            "Epoch 28/80\n",
            "78/78 [==============================] - 39s 506ms/step - loss: 0.2225 - acc: 0.9046 - val_loss: 0.1642 - val_acc: 0.9399\n",
            "Epoch 29/80\n",
            "78/78 [==============================] - 40s 509ms/step - loss: 0.2061 - acc: 0.9247 - val_loss: 0.1667 - val_acc: 0.9447\n",
            "Epoch 30/80\n",
            "78/78 [==============================] - 39s 506ms/step - loss: 0.2183 - acc: 0.9135 - val_loss: 0.1608 - val_acc: 0.9447\n",
            "Epoch 31/80\n",
            "78/78 [==============================] - 39s 505ms/step - loss: 0.2170 - acc: 0.9119 - val_loss: 0.1646 - val_acc: 0.9447\n",
            "Epoch 32/80\n",
            "78/78 [==============================] - 39s 506ms/step - loss: 0.1983 - acc: 0.9199 - val_loss: 0.1598 - val_acc: 0.9471\n",
            "Epoch 33/80\n",
            "78/78 [==============================] - 39s 506ms/step - loss: 0.2067 - acc: 0.9199 - val_loss: 0.1590 - val_acc: 0.9519\n",
            "Epoch 34/80\n",
            "78/78 [==============================] - 39s 507ms/step - loss: 0.2119 - acc: 0.9183 - val_loss: 0.1576 - val_acc: 0.9519\n",
            "Epoch 35/80\n",
            "78/78 [==============================] - 39s 505ms/step - loss: 0.2360 - acc: 0.9071 - val_loss: 0.1562 - val_acc: 0.9519\n",
            "Epoch 36/80\n",
            "78/78 [==============================] - 40s 508ms/step - loss: 0.2210 - acc: 0.9159 - val_loss: 0.1541 - val_acc: 0.9423\n",
            "Epoch 37/80\n",
            "78/78 [==============================] - 39s 504ms/step - loss: 0.2229 - acc: 0.9030 - val_loss: 0.1714 - val_acc: 0.9375\n",
            "Epoch 38/80\n",
            "78/78 [==============================] - 40s 509ms/step - loss: 0.2123 - acc: 0.9207 - val_loss: 0.1562 - val_acc: 0.9399\n",
            "Epoch 39/80\n",
            "78/78 [==============================] - 40s 507ms/step - loss: 0.2092 - acc: 0.9223 - val_loss: 0.1630 - val_acc: 0.9471\n",
            "Epoch 40/80\n",
            "78/78 [==============================] - 40s 518ms/step - loss: 0.2045 - acc: 0.9119 - val_loss: 0.1695 - val_acc: 0.9303\n",
            "Epoch 41/80\n",
            "78/78 [==============================] - 40s 515ms/step - loss: 0.2227 - acc: 0.9103 - val_loss: 0.1656 - val_acc: 0.9399\n",
            "Epoch 42/80\n",
            "78/78 [==============================] - 40s 509ms/step - loss: 0.1996 - acc: 0.9215 - val_loss: 0.1549 - val_acc: 0.9471\n",
            "Epoch 43/80\n",
            "78/78 [==============================] - 40s 512ms/step - loss: 0.2036 - acc: 0.9223 - val_loss: 0.1638 - val_acc: 0.9447\n",
            "Epoch 44/80\n",
            "78/78 [==============================] - 40s 509ms/step - loss: 0.2085 - acc: 0.9175 - val_loss: 0.1580 - val_acc: 0.9447\n",
            "Epoch 45/80\n",
            "78/78 [==============================] - 40s 512ms/step - loss: 0.2081 - acc: 0.9223 - val_loss: 0.1494 - val_acc: 0.9519\n",
            "Epoch 46/80\n",
            "78/78 [==============================] - 40s 509ms/step - loss: 0.1998 - acc: 0.9247 - val_loss: 0.1557 - val_acc: 0.9423\n",
            "Epoch 47/80\n",
            "78/78 [==============================] - 40s 511ms/step - loss: 0.2179 - acc: 0.9119 - val_loss: 0.1503 - val_acc: 0.9471\n",
            "Epoch 48/80\n",
            "78/78 [==============================] - 40s 512ms/step - loss: 0.2105 - acc: 0.9223 - val_loss: 0.1613 - val_acc: 0.9375\n",
            "Epoch 49/80\n",
            "78/78 [==============================] - 40s 513ms/step - loss: 0.2118 - acc: 0.9127 - val_loss: 0.1521 - val_acc: 0.9543\n",
            "Epoch 50/80\n",
            "78/78 [==============================] - 40s 515ms/step - loss: 0.2016 - acc: 0.9223 - val_loss: 0.1474 - val_acc: 0.9567\n",
            "Epoch 51/80\n",
            "78/78 [==============================] - 40s 517ms/step - loss: 0.1939 - acc: 0.9231 - val_loss: 0.1533 - val_acc: 0.9519\n",
            "Epoch 52/80\n",
            "78/78 [==============================] - 40s 516ms/step - loss: 0.2013 - acc: 0.9255 - val_loss: 0.1460 - val_acc: 0.9519\n",
            "Epoch 53/80\n",
            "78/78 [==============================] - 41s 528ms/step - loss: 0.1902 - acc: 0.9279 - val_loss: 0.1439 - val_acc: 0.9471\n",
            "Epoch 54/80\n",
            "78/78 [==============================] - 42s 538ms/step - loss: 0.2127 - acc: 0.9159 - val_loss: 0.1482 - val_acc: 0.9519\n",
            "Epoch 55/80\n",
            "78/78 [==============================] - 42s 534ms/step - loss: 0.1911 - acc: 0.9215 - val_loss: 0.1489 - val_acc: 0.9423\n",
            "Epoch 56/80\n",
            "78/78 [==============================] - 40s 517ms/step - loss: 0.2005 - acc: 0.9223 - val_loss: 0.1468 - val_acc: 0.9447\n",
            "Epoch 57/80\n",
            "78/78 [==============================] - 40s 513ms/step - loss: 0.1921 - acc: 0.9239 - val_loss: 0.1507 - val_acc: 0.9471\n",
            "Epoch 58/80\n",
            "78/78 [==============================] - 40s 516ms/step - loss: 0.1949 - acc: 0.9199 - val_loss: 0.1456 - val_acc: 0.9447\n",
            "Epoch 59/80\n",
            "78/78 [==============================] - 40s 508ms/step - loss: 0.2200 - acc: 0.9143 - val_loss: 0.1443 - val_acc: 0.9495\n",
            "Epoch 60/80\n",
            "78/78 [==============================] - 39s 499ms/step - loss: 0.2142 - acc: 0.9175 - val_loss: 0.1451 - val_acc: 0.9423\n",
            "Epoch 61/80\n",
            "78/78 [==============================] - 37s 476ms/step - loss: 0.1912 - acc: 0.9223 - val_loss: 0.1385 - val_acc: 0.9567\n",
            "Epoch 62/80\n",
            "78/78 [==============================] - 37s 477ms/step - loss: 0.1991 - acc: 0.9167 - val_loss: 0.1407 - val_acc: 0.9471\n",
            "Epoch 63/80\n",
            "78/78 [==============================] - 37s 475ms/step - loss: 0.2118 - acc: 0.9127 - val_loss: 0.1384 - val_acc: 0.9591\n",
            "Epoch 64/80\n",
            "78/78 [==============================] - 37s 477ms/step - loss: 0.1921 - acc: 0.9239 - val_loss: 0.1446 - val_acc: 0.9519\n",
            "Epoch 65/80\n",
            "78/78 [==============================] - 38s 485ms/step - loss: 0.1877 - acc: 0.9247 - val_loss: 0.1403 - val_acc: 0.9519\n",
            "Epoch 66/80\n",
            "78/78 [==============================] - 37s 481ms/step - loss: 0.2021 - acc: 0.9215 - val_loss: 0.1585 - val_acc: 0.9471\n",
            "Epoch 67/80\n",
            "78/78 [==============================] - 38s 486ms/step - loss: 0.1814 - acc: 0.9207 - val_loss: 0.1401 - val_acc: 0.9495\n",
            "Epoch 68/80\n",
            "78/78 [==============================] - 38s 489ms/step - loss: 0.2000 - acc: 0.9183 - val_loss: 0.1398 - val_acc: 0.9567\n",
            "Epoch 69/80\n",
            "78/78 [==============================] - 38s 487ms/step - loss: 0.2014 - acc: 0.9143 - val_loss: 0.1431 - val_acc: 0.9519\n",
            "Epoch 70/80\n",
            "78/78 [==============================] - 38s 483ms/step - loss: 0.2035 - acc: 0.9159 - val_loss: 0.1439 - val_acc: 0.9519\n",
            "Epoch 71/80\n",
            "78/78 [==============================] - 38s 485ms/step - loss: 0.2102 - acc: 0.9111 - val_loss: 0.1459 - val_acc: 0.9495\n",
            "Epoch 72/80\n",
            "78/78 [==============================] - 38s 483ms/step - loss: 0.1977 - acc: 0.9119 - val_loss: 0.1387 - val_acc: 0.9543\n",
            "Epoch 73/80\n",
            "78/78 [==============================] - 38s 487ms/step - loss: 0.2080 - acc: 0.9191 - val_loss: 0.1369 - val_acc: 0.9567\n",
            "Epoch 74/80\n",
            "78/78 [==============================] - 38s 492ms/step - loss: 0.1958 - acc: 0.9223 - val_loss: 0.1423 - val_acc: 0.9519\n",
            "Epoch 75/80\n",
            "78/78 [==============================] - 38s 483ms/step - loss: 0.1817 - acc: 0.9303 - val_loss: 0.1382 - val_acc: 0.9543\n",
            "Epoch 76/80\n",
            "78/78 [==============================] - 38s 489ms/step - loss: 0.1974 - acc: 0.9207 - val_loss: 0.1373 - val_acc: 0.9543\n",
            "Epoch 77/80\n",
            "78/78 [==============================] - 38s 485ms/step - loss: 0.1763 - acc: 0.9287 - val_loss: 0.1359 - val_acc: 0.9591\n",
            "Epoch 78/80\n",
            "78/78 [==============================] - 38s 486ms/step - loss: 0.1904 - acc: 0.9215 - val_loss: 0.1378 - val_acc: 0.9519\n",
            "Epoch 79/80\n",
            "78/78 [==============================] - 38s 489ms/step - loss: 0.2004 - acc: 0.9263 - val_loss: 0.1374 - val_acc: 0.9591\n",
            "Epoch 80/80\n",
            "78/78 [==============================] - 37s 476ms/step - loss: 0.1882 - acc: 0.9359 - val_loss: 0.1403 - val_acc: 0.9519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G90Sk0V-tg1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec97bdf-47d3-4afb-c686-629182af9d66"
      },
      "source": [
        "y_test_100x = test_generator_100x.classes\n",
        "y_pred_100x = model_100x.predict(test_generator_100x, verbose = 1)\n",
        "y_pred_100x = np.argmax(y_pred_100x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_100x, y_pred_100x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_100x, y_pred_100x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_100x, y_pred_100x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_100x, y_pred_100x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 158s 6s/step\n",
            "The Accuracy on the testing data : 93.29%\n",
            "The F1 Score on the testing data : 95.09%\n",
            "The Precision on the testing data : 94.10%\n",
            "The Recall on the testing data : 96.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkc8HDvAtg4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d0d0b6-32f4-43b6-ad15-755a24ac5531"
      },
      "source": [
        "tn_100x, fp_100x, fn_100x, tp_100x = confusion_matrix(y_test_100x, y_pred_100x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_100x)\n",
        "print('True Negitive : ',tn_100x)\n",
        "print('False Positive : ',fp_100x)\n",
        "print('False Negitive : ',fn_100x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  271\n",
            "True Negitive :  118\n",
            "False Positive :  17\n",
            "False Negitive :  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stPKijrcdEbv",
        "outputId": "48c7956c-988a-45f4-b23b-790df2786a59"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (271 / (271 + 11))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (118 / (118 + 17))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  96.10%\n",
            "Specificity :  87.41%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09C41A8ptxIK"
      },
      "source": [
        "### 200x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5-PP_2Ytg6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52fce287-1b2c-4f55-8c3b-14641c7b47ce"
      },
      "source": [
        "train_generator_200x = datagen.flow_from_directory( train_200x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_200x = datagen_test.flow_from_directory( valid_200x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_200x = datagen_test.flow_from_directory( test_200x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1207 images belonging to 2 classes.\n",
            "Found 403 images belonging to 2 classes.\n",
            "Found 403 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQssv334tg8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a41dc2-e551-4f8b-bfcb-0ad586122107"
      },
      "source": [
        "efnb_200x = EfficientNetB0(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_200x = Sequential()\n",
        "model_200x.add(efnb_200x)\n",
        "model_200x.add(GlobalAveragePooling2D())\n",
        "model_200x.add(Dropout(0.2))\n",
        "model_200x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "efnb_200x.trainable = False\n",
        "\n",
        "model_200x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "\n",
        "hist_200x = model_200x.fit(train_generator_200x, validation_data = valid_generator_200x, epochs = n_epochs, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "76/76 [==============================] - 620s 8s/step - loss: 0.4902 - acc: 0.7780 - val_loss: 0.3857 - val_acc: 0.8462\n",
            "Epoch 2/80\n",
            "76/76 [==============================] - 37s 489ms/step - loss: 0.3518 - acc: 0.8558 - val_loss: 0.3327 - val_acc: 0.8660\n",
            "Epoch 3/80\n",
            "76/76 [==============================] - 40s 521ms/step - loss: 0.3261 - acc: 0.8691 - val_loss: 0.3160 - val_acc: 0.8809\n",
            "Epoch 4/80\n",
            "76/76 [==============================] - 39s 509ms/step - loss: 0.3054 - acc: 0.8757 - val_loss: 0.2839 - val_acc: 0.8958\n",
            "Epoch 5/80\n",
            "76/76 [==============================] - 37s 486ms/step - loss: 0.2807 - acc: 0.8782 - val_loss: 0.2781 - val_acc: 0.8958\n",
            "Epoch 6/80\n",
            "76/76 [==============================] - 36s 478ms/step - loss: 0.2815 - acc: 0.8873 - val_loss: 0.2669 - val_acc: 0.9032\n",
            "Epoch 7/80\n",
            "76/76 [==============================] - 36s 476ms/step - loss: 0.2661 - acc: 0.8964 - val_loss: 0.2533 - val_acc: 0.9082\n",
            "Epoch 8/80\n",
            "76/76 [==============================] - 36s 475ms/step - loss: 0.2770 - acc: 0.8906 - val_loss: 0.2440 - val_acc: 0.9082\n",
            "Epoch 9/80\n",
            "76/76 [==============================] - 36s 474ms/step - loss: 0.2642 - acc: 0.8940 - val_loss: 0.2437 - val_acc: 0.9132\n",
            "Epoch 10/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2595 - acc: 0.8973 - val_loss: 0.2362 - val_acc: 0.9181\n",
            "Epoch 11/80\n",
            "76/76 [==============================] - 36s 475ms/step - loss: 0.2427 - acc: 0.9080 - val_loss: 0.2309 - val_acc: 0.9156\n",
            "Epoch 12/80\n",
            "76/76 [==============================] - 35s 467ms/step - loss: 0.2440 - acc: 0.9006 - val_loss: 0.2256 - val_acc: 0.9181\n",
            "Epoch 13/80\n",
            "76/76 [==============================] - 35s 465ms/step - loss: 0.2416 - acc: 0.9056 - val_loss: 0.2175 - val_acc: 0.9181\n",
            "Epoch 14/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2496 - acc: 0.9105 - val_loss: 0.2207 - val_acc: 0.9256\n",
            "Epoch 15/80\n",
            "76/76 [==============================] - 37s 485ms/step - loss: 0.2387 - acc: 0.9072 - val_loss: 0.2783 - val_acc: 0.8983\n",
            "Epoch 16/80\n",
            "76/76 [==============================] - 36s 476ms/step - loss: 0.2206 - acc: 0.9105 - val_loss: 0.2265 - val_acc: 0.9156\n",
            "Epoch 17/80\n",
            "76/76 [==============================] - 36s 474ms/step - loss: 0.2479 - acc: 0.8989 - val_loss: 0.2173 - val_acc: 0.9256\n",
            "Epoch 18/80\n",
            "76/76 [==============================] - 36s 474ms/step - loss: 0.2247 - acc: 0.9138 - val_loss: 0.2404 - val_acc: 0.9107\n",
            "Epoch 19/80\n",
            "76/76 [==============================] - 36s 474ms/step - loss: 0.2078 - acc: 0.9221 - val_loss: 0.2173 - val_acc: 0.9181\n",
            "Epoch 20/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2317 - acc: 0.9006 - val_loss: 0.2128 - val_acc: 0.9256\n",
            "Epoch 21/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2294 - acc: 0.8956 - val_loss: 0.2176 - val_acc: 0.9206\n",
            "Epoch 22/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2254 - acc: 0.9155 - val_loss: 0.2111 - val_acc: 0.9231\n",
            "Epoch 23/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2210 - acc: 0.9138 - val_loss: 0.2118 - val_acc: 0.9156\n",
            "Epoch 24/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.2186 - acc: 0.9238 - val_loss: 0.2096 - val_acc: 0.9330\n",
            "Epoch 25/80\n",
            "76/76 [==============================] - 36s 470ms/step - loss: 0.2181 - acc: 0.9163 - val_loss: 0.2198 - val_acc: 0.9231\n",
            "Epoch 26/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2178 - acc: 0.9138 - val_loss: 0.2074 - val_acc: 0.9280\n",
            "Epoch 27/80\n",
            "76/76 [==============================] - 36s 474ms/step - loss: 0.2128 - acc: 0.9180 - val_loss: 0.2095 - val_acc: 0.9231\n",
            "Epoch 28/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.2063 - acc: 0.9221 - val_loss: 0.2084 - val_acc: 0.9305\n",
            "Epoch 29/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2162 - acc: 0.9188 - val_loss: 0.2066 - val_acc: 0.9280\n",
            "Epoch 30/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.2275 - acc: 0.9114 - val_loss: 0.2176 - val_acc: 0.9280\n",
            "Epoch 31/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2208 - acc: 0.9163 - val_loss: 0.2195 - val_acc: 0.9206\n",
            "Epoch 32/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.1971 - acc: 0.9254 - val_loss: 0.2331 - val_acc: 0.9156\n",
            "Epoch 33/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.2060 - acc: 0.9180 - val_loss: 0.2299 - val_acc: 0.9206\n",
            "Epoch 34/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2168 - acc: 0.9188 - val_loss: 0.2287 - val_acc: 0.9231\n",
            "Epoch 35/80\n",
            "76/76 [==============================] - 36s 469ms/step - loss: 0.2092 - acc: 0.9180 - val_loss: 0.2124 - val_acc: 0.9280\n",
            "Epoch 36/80\n",
            "76/76 [==============================] - 36s 477ms/step - loss: 0.2146 - acc: 0.9147 - val_loss: 0.2092 - val_acc: 0.9305\n",
            "Epoch 37/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.2028 - acc: 0.9163 - val_loss: 0.2187 - val_acc: 0.9305\n",
            "Epoch 38/80\n",
            "76/76 [==============================] - 35s 467ms/step - loss: 0.2174 - acc: 0.9213 - val_loss: 0.2099 - val_acc: 0.9330\n",
            "Epoch 39/80\n",
            "76/76 [==============================] - 35s 466ms/step - loss: 0.1989 - acc: 0.9279 - val_loss: 0.2164 - val_acc: 0.9206\n",
            "Epoch 40/80\n",
            "76/76 [==============================] - 35s 468ms/step - loss: 0.2036 - acc: 0.9163 - val_loss: 0.2073 - val_acc: 0.9280\n",
            "Epoch 41/80\n",
            "76/76 [==============================] - 35s 467ms/step - loss: 0.2201 - acc: 0.9138 - val_loss: 0.2036 - val_acc: 0.9256\n",
            "Epoch 42/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.2180 - acc: 0.9064 - val_loss: 0.2132 - val_acc: 0.9330\n",
            "Epoch 43/80\n",
            "76/76 [==============================] - 35s 465ms/step - loss: 0.2062 - acc: 0.9171 - val_loss: 0.2060 - val_acc: 0.9256\n",
            "Epoch 44/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.2027 - acc: 0.9155 - val_loss: 0.2130 - val_acc: 0.9256\n",
            "Epoch 45/80\n",
            "76/76 [==============================] - 35s 465ms/step - loss: 0.2211 - acc: 0.9221 - val_loss: 0.2269 - val_acc: 0.9132\n",
            "Epoch 46/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2062 - acc: 0.9130 - val_loss: 0.1982 - val_acc: 0.9330\n",
            "Epoch 47/80\n",
            "76/76 [==============================] - 35s 467ms/step - loss: 0.2209 - acc: 0.9163 - val_loss: 0.2081 - val_acc: 0.9206\n",
            "Epoch 48/80\n",
            "76/76 [==============================] - 35s 468ms/step - loss: 0.2054 - acc: 0.9171 - val_loss: 0.2027 - val_acc: 0.9280\n",
            "Epoch 49/80\n",
            "76/76 [==============================] - 35s 466ms/step - loss: 0.1886 - acc: 0.9246 - val_loss: 0.1995 - val_acc: 0.9330\n",
            "Epoch 50/80\n",
            "76/76 [==============================] - 35s 468ms/step - loss: 0.1959 - acc: 0.9188 - val_loss: 0.2056 - val_acc: 0.9280\n",
            "Epoch 51/80\n",
            "76/76 [==============================] - 36s 469ms/step - loss: 0.2030 - acc: 0.9180 - val_loss: 0.2149 - val_acc: 0.9231\n",
            "Epoch 52/80\n",
            "76/76 [==============================] - 35s 468ms/step - loss: 0.2039 - acc: 0.9089 - val_loss: 0.2287 - val_acc: 0.9181\n",
            "Epoch 53/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.2127 - acc: 0.9171 - val_loss: 0.2014 - val_acc: 0.9181\n",
            "Epoch 54/80\n",
            "76/76 [==============================] - 35s 467ms/step - loss: 0.1940 - acc: 0.9229 - val_loss: 0.1991 - val_acc: 0.9181\n",
            "Epoch 55/80\n",
            "76/76 [==============================] - 36s 470ms/step - loss: 0.1887 - acc: 0.9279 - val_loss: 0.2101 - val_acc: 0.9256\n",
            "Epoch 56/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.2206 - acc: 0.9130 - val_loss: 0.1979 - val_acc: 0.9305\n",
            "Epoch 57/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.2085 - acc: 0.9254 - val_loss: 0.2031 - val_acc: 0.9181\n",
            "Epoch 58/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2005 - acc: 0.9122 - val_loss: 0.1977 - val_acc: 0.9280\n",
            "Epoch 59/80\n",
            "76/76 [==============================] - 36s 470ms/step - loss: 0.2261 - acc: 0.9155 - val_loss: 0.2031 - val_acc: 0.9206\n",
            "Epoch 60/80\n",
            "76/76 [==============================] - 36s 469ms/step - loss: 0.2079 - acc: 0.9171 - val_loss: 0.1947 - val_acc: 0.9256\n",
            "Epoch 61/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2141 - acc: 0.9196 - val_loss: 0.1988 - val_acc: 0.9280\n",
            "Epoch 62/80\n",
            "76/76 [==============================] - 36s 474ms/step - loss: 0.1872 - acc: 0.9345 - val_loss: 0.1899 - val_acc: 0.9256\n",
            "Epoch 63/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2223 - acc: 0.9171 - val_loss: 0.1959 - val_acc: 0.9330\n",
            "Epoch 64/80\n",
            "76/76 [==============================] - 36s 473ms/step - loss: 0.2003 - acc: 0.9246 - val_loss: 0.1937 - val_acc: 0.9380\n",
            "Epoch 65/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.1841 - acc: 0.9345 - val_loss: 0.1971 - val_acc: 0.9305\n",
            "Epoch 66/80\n",
            "76/76 [==============================] - 36s 475ms/step - loss: 0.1923 - acc: 0.9263 - val_loss: 0.1970 - val_acc: 0.9256\n",
            "Epoch 67/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2143 - acc: 0.9171 - val_loss: 0.2079 - val_acc: 0.9256\n",
            "Epoch 68/80\n",
            "76/76 [==============================] - 36s 469ms/step - loss: 0.2152 - acc: 0.9105 - val_loss: 0.1936 - val_acc: 0.9280\n",
            "Epoch 69/80\n",
            "76/76 [==============================] - 36s 469ms/step - loss: 0.2045 - acc: 0.9171 - val_loss: 0.2123 - val_acc: 0.9305\n",
            "Epoch 70/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.2032 - acc: 0.9271 - val_loss: 0.2002 - val_acc: 0.9305\n",
            "Epoch 71/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.1934 - acc: 0.9271 - val_loss: 0.1929 - val_acc: 0.9181\n",
            "Epoch 72/80\n",
            "76/76 [==============================] - 36s 471ms/step - loss: 0.2042 - acc: 0.9188 - val_loss: 0.1982 - val_acc: 0.9256\n",
            "Epoch 73/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.1940 - acc: 0.9254 - val_loss: 0.1948 - val_acc: 0.9231\n",
            "Epoch 74/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.1857 - acc: 0.9304 - val_loss: 0.1984 - val_acc: 0.9280\n",
            "Epoch 75/80\n",
            "76/76 [==============================] - 36s 468ms/step - loss: 0.2114 - acc: 0.9130 - val_loss: 0.1973 - val_acc: 0.9206\n",
            "Epoch 76/80\n",
            "76/76 [==============================] - 36s 470ms/step - loss: 0.2025 - acc: 0.9039 - val_loss: 0.2245 - val_acc: 0.9181\n",
            "Epoch 77/80\n",
            "76/76 [==============================] - 36s 469ms/step - loss: 0.1834 - acc: 0.9221 - val_loss: 0.2037 - val_acc: 0.9305\n",
            "Epoch 78/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.1806 - acc: 0.9287 - val_loss: 0.2021 - val_acc: 0.9231\n",
            "Epoch 79/80\n",
            "76/76 [==============================] - 35s 466ms/step - loss: 0.1992 - acc: 0.9205 - val_loss: 0.1962 - val_acc: 0.9231\n",
            "Epoch 80/80\n",
            "76/76 [==============================] - 36s 472ms/step - loss: 0.2036 - acc: 0.9130 - val_loss: 0.2115 - val_acc: 0.9256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTjS18lt-5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82a42b7-b746-49e1-de49-791dc2d2d8cb"
      },
      "source": [
        "y_test_200x = test_generator_200x.classes\n",
        "y_pred_200x = model_200x.predict(test_generator_200x, verbose = 1)\n",
        "y_pred_200x = np.argmax(y_pred_200x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_200x, y_pred_200x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_200x, y_pred_200x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_200x, y_pred_200x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_200x, y_pred_200x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 143s 6s/step\n",
            "The Accuracy on the testing data : 91.81%\n",
            "The F1 Score on the testing data : 93.94%\n",
            "The Precision on the testing data : 96.24%\n",
            "The Recall on the testing data : 91.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iorF1356t-86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea23b753-5969-42d4-80fb-88b54ed3c487"
      },
      "source": [
        "tn_200x, fp_200x, fn_200x, tp_200x = confusion_matrix(y_test_200x, y_pred_200x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_200x)\n",
        "print('True Negitive : ',tn_200x)\n",
        "print('False Positive : ',fp_200x)\n",
        "print('False Negitive : ',fn_200x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  256\n",
            "True Negitive :  114\n",
            "False Positive :  10\n",
            "False Negitive :  23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ3XlG9ScT_G",
        "outputId": "fd990691-b456-41d4-ad1a-6a8618c13323"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (256 / (256 + 23))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (114 / (114 + 10))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  91.76%\n",
            "Specificity :  91.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWtWA2peuFlH"
      },
      "source": [
        "### 400x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me6XQ6ust_Fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ad0215-4068-48c2-ff30-8ec63a0ff98b"
      },
      "source": [
        "train_generator_400x = datagen.flow_from_directory( train_400x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_400x = datagen_test.flow_from_directory( valid_400x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_400x = datagen_test.flow_from_directory( test_400x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1092 images belonging to 2 classes.\n",
            "Found 364 images belonging to 2 classes.\n",
            "Found 364 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5tDTX63t_Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a17329a-7f93-49e3-c9b6-b77aecc31b9c"
      },
      "source": [
        "efnb_400x = EfficientNetB0(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_400x = Sequential()\n",
        "model_400x.add(efnb_400x)\n",
        "model_400x.add(GlobalAveragePooling2D())\n",
        "model_400x.add(Dropout(0.2))\n",
        "model_400x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "efnb_400x.trainable = False\n",
        "\n",
        "model_400x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "\n",
        "hist_400x = model_400x.fit(train_generator_400x, validation_data = valid_generator_400x, epochs = n_epochs, verbose = 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Epoch 1/80\n",
            "69/69 [==============================] - 575s 8s/step - loss: 0.5288 - acc: 0.7408 - val_loss: 0.4377 - val_acc: 0.8132\n",
            "Epoch 2/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.4259 - acc: 0.8168 - val_loss: 0.4005 - val_acc: 0.8489\n",
            "Epoch 3/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3839 - acc: 0.8498 - val_loss: 0.3781 - val_acc: 0.8489\n",
            "Epoch 4/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3756 - acc: 0.8507 - val_loss: 0.3678 - val_acc: 0.8544\n",
            "Epoch 5/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3407 - acc: 0.8571 - val_loss: 0.3531 - val_acc: 0.8626\n",
            "Epoch 6/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3542 - acc: 0.8526 - val_loss: 0.3483 - val_acc: 0.8626\n",
            "Epoch 7/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3230 - acc: 0.8626 - val_loss: 0.3474 - val_acc: 0.8599\n",
            "Epoch 8/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3312 - acc: 0.8645 - val_loss: 0.3347 - val_acc: 0.8681\n",
            "Epoch 9/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3267 - acc: 0.8590 - val_loss: 0.3269 - val_acc: 0.8736\n",
            "Epoch 10/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3219 - acc: 0.8690 - val_loss: 0.3173 - val_acc: 0.8929\n",
            "Epoch 11/80\n",
            "69/69 [==============================] - 92s 1s/step - loss: 0.3091 - acc: 0.8681 - val_loss: 0.3155 - val_acc: 0.8791\n",
            "Epoch 12/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.3151 - acc: 0.8736 - val_loss: 0.3152 - val_acc: 0.8736\n",
            "Epoch 13/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.3102 - acc: 0.8718 - val_loss: 0.3308 - val_acc: 0.8709\n",
            "Epoch 14/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.3031 - acc: 0.8782 - val_loss: 0.3455 - val_acc: 0.8654\n",
            "Epoch 15/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2974 - acc: 0.8800 - val_loss: 0.3179 - val_acc: 0.8791\n",
            "Epoch 16/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.3290 - acc: 0.8471 - val_loss: 0.3118 - val_acc: 0.8846\n",
            "Epoch 17/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.3004 - acc: 0.8810 - val_loss: 0.3253 - val_acc: 0.8654\n",
            "Epoch 18/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2823 - acc: 0.8837 - val_loss: 0.3131 - val_acc: 0.8846\n",
            "Epoch 19/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2861 - acc: 0.8864 - val_loss: 0.3085 - val_acc: 0.8846\n",
            "Epoch 20/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2787 - acc: 0.8864 - val_loss: 0.3117 - val_acc: 0.8984\n",
            "Epoch 21/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2775 - acc: 0.8864 - val_loss: 0.3143 - val_acc: 0.8819\n",
            "Epoch 22/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2866 - acc: 0.8874 - val_loss: 0.3194 - val_acc: 0.8764\n",
            "Epoch 23/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2844 - acc: 0.8947 - val_loss: 0.3065 - val_acc: 0.8791\n",
            "Epoch 24/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2907 - acc: 0.8810 - val_loss: 0.3040 - val_acc: 0.8846\n",
            "Epoch 25/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2773 - acc: 0.8828 - val_loss: 0.3069 - val_acc: 0.8874\n",
            "Epoch 26/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2882 - acc: 0.8910 - val_loss: 0.2954 - val_acc: 0.8819\n",
            "Epoch 27/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2908 - acc: 0.8846 - val_loss: 0.3037 - val_acc: 0.8791\n",
            "Epoch 28/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2935 - acc: 0.8846 - val_loss: 0.2979 - val_acc: 0.8874\n",
            "Epoch 29/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2904 - acc: 0.8910 - val_loss: 0.2929 - val_acc: 0.8874\n",
            "Epoch 30/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2797 - acc: 0.8800 - val_loss: 0.2983 - val_acc: 0.8874\n",
            "Epoch 31/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2627 - acc: 0.9048 - val_loss: 0.2972 - val_acc: 0.8929\n",
            "Epoch 32/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2785 - acc: 0.8919 - val_loss: 0.3031 - val_acc: 0.8819\n",
            "Epoch 33/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2603 - acc: 0.8947 - val_loss: 0.2976 - val_acc: 0.8819\n",
            "Epoch 34/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2640 - acc: 0.9011 - val_loss: 0.2948 - val_acc: 0.8819\n",
            "Epoch 35/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2874 - acc: 0.8864 - val_loss: 0.3048 - val_acc: 0.8901\n",
            "Epoch 36/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2674 - acc: 0.8929 - val_loss: 0.3026 - val_acc: 0.8791\n",
            "Epoch 37/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2633 - acc: 0.8929 - val_loss: 0.2985 - val_acc: 0.8819\n",
            "Epoch 38/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2675 - acc: 0.8984 - val_loss: 0.2962 - val_acc: 0.8901\n",
            "Epoch 39/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2468 - acc: 0.8984 - val_loss: 0.2978 - val_acc: 0.8956\n",
            "Epoch 40/80\n",
            "69/69 [==============================] - 91s 1s/step - loss: 0.2623 - acc: 0.8892 - val_loss: 0.3153 - val_acc: 0.8819\n",
            "Epoch 41/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2674 - acc: 0.8892 - val_loss: 0.2976 - val_acc: 0.8874\n",
            "Epoch 42/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2565 - acc: 0.8819 - val_loss: 0.2903 - val_acc: 0.8874\n",
            "Epoch 43/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2505 - acc: 0.8947 - val_loss: 0.2884 - val_acc: 0.8901\n",
            "Epoch 44/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2698 - acc: 0.8874 - val_loss: 0.2928 - val_acc: 0.8901\n",
            "Epoch 45/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2651 - acc: 0.8910 - val_loss: 0.2922 - val_acc: 0.8819\n",
            "Epoch 46/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2816 - acc: 0.8736 - val_loss: 0.2914 - val_acc: 0.8929\n",
            "Epoch 47/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2661 - acc: 0.8965 - val_loss: 0.2924 - val_acc: 0.8819\n",
            "Epoch 48/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2611 - acc: 0.8910 - val_loss: 0.2904 - val_acc: 0.8874\n",
            "Epoch 49/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2513 - acc: 0.8984 - val_loss: 0.3092 - val_acc: 0.8956\n",
            "Epoch 50/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2821 - acc: 0.8810 - val_loss: 0.2876 - val_acc: 0.8874\n",
            "Epoch 51/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2657 - acc: 0.8984 - val_loss: 0.2920 - val_acc: 0.8901\n",
            "Epoch 52/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2757 - acc: 0.8819 - val_loss: 0.3025 - val_acc: 0.8846\n",
            "Epoch 53/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2553 - acc: 0.8974 - val_loss: 0.2953 - val_acc: 0.8901\n",
            "Epoch 54/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2819 - acc: 0.8855 - val_loss: 0.3139 - val_acc: 0.8819\n",
            "Epoch 55/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2801 - acc: 0.8910 - val_loss: 0.2912 - val_acc: 0.8901\n",
            "Epoch 56/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2630 - acc: 0.8855 - val_loss: 0.2933 - val_acc: 0.8846\n",
            "Epoch 57/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2801 - acc: 0.8910 - val_loss: 0.3236 - val_acc: 0.8819\n",
            "Epoch 58/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2739 - acc: 0.8800 - val_loss: 0.2892 - val_acc: 0.8874\n",
            "Epoch 59/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2239 - acc: 0.9185 - val_loss: 0.2910 - val_acc: 0.8956\n",
            "Epoch 60/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2530 - acc: 0.8828 - val_loss: 0.2943 - val_acc: 0.8846\n",
            "Epoch 61/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2501 - acc: 0.9121 - val_loss: 0.3000 - val_acc: 0.8874\n",
            "Epoch 62/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2361 - acc: 0.9048 - val_loss: 0.3057 - val_acc: 0.8901\n",
            "Epoch 63/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2707 - acc: 0.8855 - val_loss: 0.2892 - val_acc: 0.8984\n",
            "Epoch 64/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2445 - acc: 0.9002 - val_loss: 0.2980 - val_acc: 0.8901\n",
            "Epoch 65/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2573 - acc: 0.8965 - val_loss: 0.2897 - val_acc: 0.8874\n",
            "Epoch 66/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2577 - acc: 0.9048 - val_loss: 0.2965 - val_acc: 0.8874\n",
            "Epoch 67/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2423 - acc: 0.8984 - val_loss: 0.2910 - val_acc: 0.8901\n",
            "Epoch 68/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2571 - acc: 0.8929 - val_loss: 0.2918 - val_acc: 0.8846\n",
            "Epoch 69/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2826 - acc: 0.8864 - val_loss: 0.3069 - val_acc: 0.8929\n",
            "Epoch 70/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2379 - acc: 0.9029 - val_loss: 0.3055 - val_acc: 0.8874\n",
            "Epoch 71/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2637 - acc: 0.9011 - val_loss: 0.2897 - val_acc: 0.8956\n",
            "Epoch 72/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2535 - acc: 0.8883 - val_loss: 0.3089 - val_acc: 0.8956\n",
            "Epoch 73/80\n",
            "69/69 [==============================] - 89s 1s/step - loss: 0.2641 - acc: 0.8864 - val_loss: 0.2917 - val_acc: 0.8984\n",
            "Epoch 74/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2554 - acc: 0.9038 - val_loss: 0.2951 - val_acc: 0.8901\n",
            "Epoch 75/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2535 - acc: 0.8901 - val_loss: 0.2970 - val_acc: 0.8901\n",
            "Epoch 76/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2606 - acc: 0.8965 - val_loss: 0.3071 - val_acc: 0.8901\n",
            "Epoch 77/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2534 - acc: 0.9002 - val_loss: 0.2954 - val_acc: 0.8956\n",
            "Epoch 78/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2469 - acc: 0.9002 - val_loss: 0.2932 - val_acc: 0.8901\n",
            "Epoch 79/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2430 - acc: 0.8984 - val_loss: 0.3131 - val_acc: 0.8956\n",
            "Epoch 80/80\n",
            "69/69 [==============================] - 90s 1s/step - loss: 0.2560 - acc: 0.8892 - val_loss: 0.2897 - val_acc: 0.8929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XobF5uKcuU3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2927e04-e39e-4826-dcb5-7ae68036ecc6"
      },
      "source": [
        "y_test_400x = test_generator_400x.classes\n",
        "y_pred_400x = model_400x.predict(test_generator_400x, verbose = 1)\n",
        "y_pred_400x = np.argmax(y_pred_400x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_400x, y_pred_400x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_400x, y_pred_400x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_400x, y_pred_400x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_400x, y_pred_400x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 124s 6s/step\n",
            "The Accuracy on the testing data : 88.19%\n",
            "The F1 Score on the testing data : 91.24%\n",
            "The Precision on the testing data : 88.54%\n",
            "The Recall on the testing data : 94.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icn6qS6uXdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526476eb-c81f-4eb9-e292-0f2c015a85dc"
      },
      "source": [
        "tn_400x, fp_400x, fn_400x, tp_400x = confusion_matrix(y_test_400x, y_pred_400x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_400x)\n",
        "print('True Negitive : ',tn_400x)\n",
        "print('False Positive : ',fp_400x)\n",
        "print('False Negitive : ',fn_400x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  224\n",
            "True Negitive :  97\n",
            "False Positive :  29\n",
            "False Negitive :  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQI7wpK-R021",
        "outputId": "00b0ab37-d91e-4489-e431-7ffcfde48b61"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (224 / (224 + 14))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (97 / (97 + 29))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  94.12%\n",
            "Specificity :  76.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcEs_WlQ4Pfh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}