{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXq4fvnmBMMpKUTt2vwAZr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayazzazay/MRP/blob/main/MobileNetV2_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvvPjLYxrvV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cfc37d-123b-4c90-e82c-f0b7f6d0825a"
      },
      "source": [
        "# to upload the dataset folder to colab from google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRHEW3JbrxHL"
      },
      "source": [
        "# importing libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.utils import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjofawesrxJm"
      },
      "source": [
        "# getting the paths of train and test data\n",
        "\n",
        "train_40x_path = '/content/drive/MyDrive/breast_cancer_data/train_40x'\n",
        "test_40x_path = '/content/drive/MyDrive/breast_cancer_data/test_40x'\n",
        "valid_40x_path = '/content/drive/MyDrive/breast_cancer_data/valid_40x'\n",
        "\n",
        "train_100x_path = '/content/drive/MyDrive/breast_cancer_data/train_100x'\n",
        "test_100x_path = '/content/drive/MyDrive/breast_cancer_data/test_100x'\n",
        "valid_100x_path = '/content/drive/MyDrive/breast_cancer_data/valid_100x'\n",
        "\n",
        "train_200x_path = '/content/drive/MyDrive/breast_cancer_data/train_200x'\n",
        "test_200x_path = '/content/drive/MyDrive/breast_cancer_data/test_200x'\n",
        "valid_200x_path = '/content/drive/MyDrive/breast_cancer_data/valid_200x'\n",
        "\n",
        "train_400x_path = '/content/drive/MyDrive/breast_cancer_data/train_400x'\n",
        "test_400x_path = '/content/drive/MyDrive/breast_cancer_data/test_400x'\n",
        "valid_400x_path = '/content/drive/MyDrive/breast_cancer_data/valid_400x'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA5bt7wtrxMj"
      },
      "source": [
        "n_epochs = 80\n",
        "height = 224\n",
        "width = 224\n",
        "channels = 3\n",
        "input_shape = (height, width, channels)\n",
        "n_classes = 2\n",
        "lr = 1e-3\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J1iyqOOrxPC"
      },
      "source": [
        "datagen = ImageDataGenerator( horizontal_flip = True, rotation_range=40, fill_mode = 'reflect', width_shift_range = 0.2, height_shift_range = 0.2, vertical_flip=True, preprocessing_function = preprocess_input)\n",
        "datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4AaZDvir8Jb"
      },
      "source": [
        "### 40x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j96fbrWDrxRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8034f478-3324-4538-d916-5d6d512dfa86"
      },
      "source": [
        "train_generator_40x = datagen.flow_from_directory( train_40x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_40x = datagen_test.flow_from_directory( valid_40x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_40x = datagen_test.flow_from_directory( test_40x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1197 images belonging to 2 classes.\n",
            "Found 399 images belonging to 2 classes.\n",
            "Found 399 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJqqIvsrxUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89058ac-428f-4f48-efa6-b8be1916a8be"
      },
      "source": [
        "mob_40x = MobileNetV2(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_40x = Sequential()\n",
        "model_40x.add(mob_40x)\n",
        "model_40x.add(GlobalAveragePooling2D())\n",
        "model_40x.add(Dropout(0.2))\n",
        "model_40x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "mob_40x.trainable = False\n",
        "\n",
        "model_40x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "hist_40x = model_40x.fit(train_generator_40x, validation_data = valid_generator_40x, epochs = n_epochs, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/80\n",
            "75/75 [==============================] - 449s 6s/step - loss: 0.6572 - acc: 0.6942 - val_loss: 0.4309 - val_acc: 0.8145\n",
            "Epoch 2/80\n",
            "75/75 [==============================] - 79s 1s/step - loss: 0.4993 - acc: 0.7636 - val_loss: 0.3724 - val_acc: 0.8321\n",
            "Epoch 3/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.4434 - acc: 0.7970 - val_loss: 0.3442 - val_acc: 0.8496\n",
            "Epoch 4/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.4058 - acc: 0.8321 - val_loss: 0.3554 - val_acc: 0.8496\n",
            "Epoch 5/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.4091 - acc: 0.8137 - val_loss: 0.3477 - val_acc: 0.8596\n",
            "Epoch 6/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.3941 - acc: 0.8087 - val_loss: 0.3140 - val_acc: 0.8722\n",
            "Epoch 7/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.3597 - acc: 0.8505 - val_loss: 0.3051 - val_acc: 0.8822\n",
            "Epoch 8/80\n",
            "75/75 [==============================] - 79s 1s/step - loss: 0.3510 - acc: 0.8463 - val_loss: 0.4157 - val_acc: 0.7895\n",
            "Epoch 9/80\n",
            "75/75 [==============================] - 79s 1s/step - loss: 0.3407 - acc: 0.8571 - val_loss: 0.3610 - val_acc: 0.8346\n",
            "Epoch 10/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.3185 - acc: 0.8605 - val_loss: 0.2947 - val_acc: 0.8847\n",
            "Epoch 11/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.3432 - acc: 0.8438 - val_loss: 0.2953 - val_acc: 0.8747\n",
            "Epoch 12/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.3183 - acc: 0.8663 - val_loss: 0.3321 - val_acc: 0.8546\n",
            "Epoch 13/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3377 - acc: 0.8488 - val_loss: 0.2803 - val_acc: 0.8747\n",
            "Epoch 14/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3240 - acc: 0.8655 - val_loss: 0.2986 - val_acc: 0.8747\n",
            "Epoch 15/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3109 - acc: 0.8755 - val_loss: 0.3032 - val_acc: 0.8571\n",
            "Epoch 16/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.2922 - acc: 0.8822 - val_loss: 0.3190 - val_acc: 0.8697\n",
            "Epoch 17/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3239 - acc: 0.8588 - val_loss: 0.2929 - val_acc: 0.8722\n",
            "Epoch 18/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3144 - acc: 0.8596 - val_loss: 0.3045 - val_acc: 0.8521\n",
            "Epoch 19/80\n",
            "75/75 [==============================] - 81s 1s/step - loss: 0.3225 - acc: 0.8613 - val_loss: 0.2828 - val_acc: 0.8697\n",
            "Epoch 20/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.3070 - acc: 0.8697 - val_loss: 0.2745 - val_acc: 0.8772\n",
            "Epoch 21/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.3060 - acc: 0.8789 - val_loss: 0.3224 - val_acc: 0.8496\n",
            "Epoch 22/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.2898 - acc: 0.8747 - val_loss: 0.2676 - val_acc: 0.8822\n",
            "Epoch 23/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2954 - acc: 0.8705 - val_loss: 0.2766 - val_acc: 0.8722\n",
            "Epoch 24/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2903 - acc: 0.8797 - val_loss: 0.2926 - val_acc: 0.8772\n",
            "Epoch 25/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3123 - acc: 0.8613 - val_loss: 0.2658 - val_acc: 0.8872\n",
            "Epoch 26/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2959 - acc: 0.8705 - val_loss: 0.2741 - val_acc: 0.8897\n",
            "Epoch 27/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.2935 - acc: 0.8730 - val_loss: 0.2927 - val_acc: 0.8847\n",
            "Epoch 28/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2847 - acc: 0.8830 - val_loss: 0.2766 - val_acc: 0.8797\n",
            "Epoch 29/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2674 - acc: 0.8922 - val_loss: 0.2554 - val_acc: 0.8847\n",
            "Epoch 30/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.3068 - acc: 0.8747 - val_loss: 0.2602 - val_acc: 0.8822\n",
            "Epoch 31/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2789 - acc: 0.8722 - val_loss: 0.2584 - val_acc: 0.8897\n",
            "Epoch 32/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2764 - acc: 0.8889 - val_loss: 0.2552 - val_acc: 0.8797\n",
            "Epoch 33/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2981 - acc: 0.8672 - val_loss: 0.3496 - val_acc: 0.8471\n",
            "Epoch 34/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2652 - acc: 0.8872 - val_loss: 0.2623 - val_acc: 0.8872\n",
            "Epoch 35/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2672 - acc: 0.8906 - val_loss: 0.2483 - val_acc: 0.8897\n",
            "Epoch 36/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.3215 - acc: 0.8613 - val_loss: 0.2788 - val_acc: 0.8747\n",
            "Epoch 37/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2959 - acc: 0.8830 - val_loss: 0.2840 - val_acc: 0.8772\n",
            "Epoch 38/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2760 - acc: 0.8789 - val_loss: 0.2779 - val_acc: 0.8672\n",
            "Epoch 39/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2869 - acc: 0.8755 - val_loss: 0.2771 - val_acc: 0.8797\n",
            "Epoch 40/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2757 - acc: 0.8805 - val_loss: 0.4036 - val_acc: 0.8421\n",
            "Epoch 41/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2942 - acc: 0.8897 - val_loss: 0.2939 - val_acc: 0.8872\n",
            "Epoch 42/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.2592 - acc: 0.8906 - val_loss: 0.3185 - val_acc: 0.8897\n",
            "Epoch 43/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2729 - acc: 0.8839 - val_loss: 0.2494 - val_acc: 0.8897\n",
            "Epoch 44/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2914 - acc: 0.8755 - val_loss: 0.2556 - val_acc: 0.8922\n",
            "Epoch 45/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.2486 - acc: 0.8931 - val_loss: 0.2598 - val_acc: 0.8822\n",
            "Epoch 46/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3045 - acc: 0.8688 - val_loss: 0.2914 - val_acc: 0.8872\n",
            "Epoch 47/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.2825 - acc: 0.8797 - val_loss: 0.2596 - val_acc: 0.8847\n",
            "Epoch 48/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3148 - acc: 0.8638 - val_loss: 0.2651 - val_acc: 0.8822\n",
            "Epoch 49/80\n",
            "75/75 [==============================] - 81s 1s/step - loss: 0.2831 - acc: 0.8789 - val_loss: 0.3019 - val_acc: 0.8797\n",
            "Epoch 50/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2748 - acc: 0.8830 - val_loss: 0.2767 - val_acc: 0.8722\n",
            "Epoch 51/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.2906 - acc: 0.8705 - val_loss: 0.2767 - val_acc: 0.8797\n",
            "Epoch 52/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2692 - acc: 0.8881 - val_loss: 0.2713 - val_acc: 0.8897\n",
            "Epoch 53/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.3058 - acc: 0.8789 - val_loss: 0.2636 - val_acc: 0.8822\n",
            "Epoch 54/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.2793 - acc: 0.8881 - val_loss: 0.3168 - val_acc: 0.8747\n",
            "Epoch 55/80\n",
            "75/75 [==============================] - 78s 1s/step - loss: 0.2889 - acc: 0.8889 - val_loss: 0.2868 - val_acc: 0.8822\n",
            "Epoch 56/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2771 - acc: 0.8847 - val_loss: 0.2662 - val_acc: 0.8847\n",
            "Epoch 57/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2566 - acc: 0.8914 - val_loss: 0.2556 - val_acc: 0.9073\n",
            "Epoch 58/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2603 - acc: 0.8864 - val_loss: 0.2703 - val_acc: 0.8897\n",
            "Epoch 59/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2848 - acc: 0.8789 - val_loss: 0.3014 - val_acc: 0.8797\n",
            "Epoch 60/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2678 - acc: 0.8956 - val_loss: 0.2767 - val_acc: 0.8747\n",
            "Epoch 61/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2890 - acc: 0.8739 - val_loss: 0.2639 - val_acc: 0.8772\n",
            "Epoch 62/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2870 - acc: 0.8747 - val_loss: 0.2874 - val_acc: 0.8847\n",
            "Epoch 63/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2846 - acc: 0.8747 - val_loss: 0.2500 - val_acc: 0.8972\n",
            "Epoch 64/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2672 - acc: 0.8947 - val_loss: 0.2649 - val_acc: 0.8947\n",
            "Epoch 65/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2749 - acc: 0.8755 - val_loss: 0.2481 - val_acc: 0.8972\n",
            "Epoch 66/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2688 - acc: 0.8830 - val_loss: 0.2549 - val_acc: 0.8997\n",
            "Epoch 67/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2732 - acc: 0.8906 - val_loss: 0.2525 - val_acc: 0.8922\n",
            "Epoch 68/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2701 - acc: 0.8906 - val_loss: 0.2878 - val_acc: 0.8872\n",
            "Epoch 69/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.3004 - acc: 0.8730 - val_loss: 0.2612 - val_acc: 0.8972\n",
            "Epoch 70/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2707 - acc: 0.8872 - val_loss: 0.2580 - val_acc: 0.8922\n",
            "Epoch 71/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2608 - acc: 0.8872 - val_loss: 0.2492 - val_acc: 0.8897\n",
            "Epoch 72/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2827 - acc: 0.8881 - val_loss: 0.2728 - val_acc: 0.8972\n",
            "Epoch 73/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2898 - acc: 0.8855 - val_loss: 0.2456 - val_acc: 0.8922\n",
            "Epoch 74/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.2793 - acc: 0.8939 - val_loss: 0.2483 - val_acc: 0.8822\n",
            "Epoch 75/80\n",
            "75/75 [==============================] - 76s 1s/step - loss: 0.2827 - acc: 0.8814 - val_loss: 0.2503 - val_acc: 0.8972\n",
            "Epoch 76/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2593 - acc: 0.8897 - val_loss: 0.2355 - val_acc: 0.8947\n",
            "Epoch 77/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2860 - acc: 0.8797 - val_loss: 0.2402 - val_acc: 0.8972\n",
            "Epoch 78/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2549 - acc: 0.8906 - val_loss: 0.2403 - val_acc: 0.8947\n",
            "Epoch 79/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2610 - acc: 0.8864 - val_loss: 0.2364 - val_acc: 0.9073\n",
            "Epoch 80/80\n",
            "75/75 [==============================] - 77s 1s/step - loss: 0.2562 - acc: 0.8981 - val_loss: 0.2396 - val_acc: 0.9023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3xuwU0SrxZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247f3949-4fb5-43ee-f4e0-2e41f8969948"
      },
      "source": [
        "y_test_40x = test_generator_40x.classes\n",
        "y_pred_40x = model_40x.predict(test_generator_40x, verbose = 1)\n",
        "y_pred_40x = np.argmax(y_pred_40x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_40x, y_pred_40x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_40x, y_pred_40x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_40x, y_pred_40x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_40x, y_pred_40x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 106s 4s/step\n",
            "The Accuracy on the testing data : 90.48%\n",
            "The F1 Score on the testing data : 93.17%\n",
            "The Precision on the testing data : 92.50%\n",
            "The Recall on the testing data : 93.84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alF-FEQ3sUIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea028bab-c40a-4d64-975b-cc7cac07763f"
      },
      "source": [
        "tn_40x, fp_40x, fn_40x, tp_40x = confusion_matrix(y_test_40x, y_pred_40x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_40x)\n",
        "print('True Negitive : ',tn_40x)\n",
        "print('False Positive : ',fp_40x)\n",
        "print('False Negitive : ',fn_40x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  259\n",
            "True Negitive :  102\n",
            "False Positive :  21\n",
            "False Negitive :  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvGyUEss4_WV",
        "outputId": "25fec97f-a7d1-4c7a-869c-7bcc45985db2"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (259 / (259 + 17))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (102 / (102 + 21))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  93.84%\n",
            "Specificity :  82.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrS5ox0_sU_y"
      },
      "source": [
        "### 100x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htPMLPPosXwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e8c702-a982-4682-9fb6-1cc9e11d5869"
      },
      "source": [
        "train_generator_100x = datagen.flow_from_directory( train_100x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_100x = datagen_test.flow_from_directory( valid_100x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_100x = datagen_test.flow_from_directory( test_100x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1248 images belonging to 2 classes.\n",
            "Found 416 images belonging to 2 classes.\n",
            "Found 417 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOP3bG0etgws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7b3b98-5adc-498e-d1ea-757a6819c66c"
      },
      "source": [
        "mob_100x = MobileNetV2(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_100x = Sequential()\n",
        "model_100x.add(mob_100x)\n",
        "model_100x.add(GlobalAveragePooling2D())\n",
        "model_100x.add(Dropout(0.2))\n",
        "model_100x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "mob_100x.trainable = False\n",
        "\n",
        "model_100x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "\n",
        "hist_100x = model_100x.fit(train_generator_100x, validation_data = valid_generator_100x, epochs = n_epochs, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "78/78 [==============================] - 493s 6s/step - loss: 0.6387 - acc: 0.7091 - val_loss: 0.4352 - val_acc: 0.7957\n",
            "Epoch 2/80\n",
            "78/78 [==============================] - 87s 1s/step - loss: 0.4896 - acc: 0.7812 - val_loss: 0.3743 - val_acc: 0.8173\n",
            "Epoch 3/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.4539 - acc: 0.8005 - val_loss: 0.3610 - val_acc: 0.8389\n",
            "Epoch 4/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.4474 - acc: 0.7861 - val_loss: 0.3400 - val_acc: 0.8486\n",
            "Epoch 5/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.4188 - acc: 0.8125 - val_loss: 0.3081 - val_acc: 0.8726\n",
            "Epoch 6/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.4145 - acc: 0.8061 - val_loss: 0.3023 - val_acc: 0.8750\n",
            "Epoch 7/80\n",
            "78/78 [==============================] - 84s 1s/step - loss: 0.3698 - acc: 0.8454 - val_loss: 0.3042 - val_acc: 0.8678\n",
            "Epoch 8/80\n",
            "78/78 [==============================] - 84s 1s/step - loss: 0.3685 - acc: 0.8421 - val_loss: 0.2994 - val_acc: 0.8702\n",
            "Epoch 9/80\n",
            "78/78 [==============================] - 84s 1s/step - loss: 0.3738 - acc: 0.8349 - val_loss: 0.2883 - val_acc: 0.8750\n",
            "Epoch 10/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3688 - acc: 0.8413 - val_loss: 0.2860 - val_acc: 0.8750\n",
            "Epoch 11/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3498 - acc: 0.8558 - val_loss: 0.2974 - val_acc: 0.8678\n",
            "Epoch 12/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3336 - acc: 0.8566 - val_loss: 0.2876 - val_acc: 0.8870\n",
            "Epoch 13/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3419 - acc: 0.8494 - val_loss: 0.2767 - val_acc: 0.8846\n",
            "Epoch 14/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3438 - acc: 0.8518 - val_loss: 0.2639 - val_acc: 0.8870\n",
            "Epoch 15/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3394 - acc: 0.8454 - val_loss: 0.3261 - val_acc: 0.8534\n",
            "Epoch 16/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3206 - acc: 0.8662 - val_loss: 0.2727 - val_acc: 0.8918\n",
            "Epoch 17/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3218 - acc: 0.8534 - val_loss: 0.2820 - val_acc: 0.8678\n",
            "Epoch 18/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3103 - acc: 0.8694 - val_loss: 0.3323 - val_acc: 0.8462\n",
            "Epoch 19/80\n",
            "78/78 [==============================] - 84s 1s/step - loss: 0.3347 - acc: 0.8518 - val_loss: 0.2641 - val_acc: 0.8966\n",
            "Epoch 20/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3250 - acc: 0.8542 - val_loss: 0.2704 - val_acc: 0.8798\n",
            "Epoch 21/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3107 - acc: 0.8614 - val_loss: 0.2635 - val_acc: 0.8846\n",
            "Epoch 22/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3375 - acc: 0.8526 - val_loss: 0.2794 - val_acc: 0.8798\n",
            "Epoch 23/80\n",
            "78/78 [==============================] - 84s 1s/step - loss: 0.3126 - acc: 0.8718 - val_loss: 0.2858 - val_acc: 0.8726\n",
            "Epoch 24/80\n",
            "78/78 [==============================] - 84s 1s/step - loss: 0.3156 - acc: 0.8502 - val_loss: 0.2567 - val_acc: 0.8942\n",
            "Epoch 25/80\n",
            "78/78 [==============================] - 85s 1s/step - loss: 0.3068 - acc: 0.8742 - val_loss: 0.3096 - val_acc: 0.8726\n",
            "Epoch 26/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3226 - acc: 0.8590 - val_loss: 0.2600 - val_acc: 0.8846\n",
            "Epoch 27/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3326 - acc: 0.8566 - val_loss: 0.2531 - val_acc: 0.8870\n",
            "Epoch 28/80\n",
            "78/78 [==============================] - 84s 1s/step - loss: 0.3300 - acc: 0.8598 - val_loss: 0.2668 - val_acc: 0.8726\n",
            "Epoch 29/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3224 - acc: 0.8542 - val_loss: 0.2507 - val_acc: 0.8846\n",
            "Epoch 30/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3086 - acc: 0.8582 - val_loss: 0.2583 - val_acc: 0.8822\n",
            "Epoch 31/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3303 - acc: 0.8470 - val_loss: 0.2592 - val_acc: 0.8822\n",
            "Epoch 32/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3054 - acc: 0.8646 - val_loss: 0.2430 - val_acc: 0.8942\n",
            "Epoch 33/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3126 - acc: 0.8750 - val_loss: 0.2378 - val_acc: 0.8990\n",
            "Epoch 34/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3135 - acc: 0.8622 - val_loss: 0.2570 - val_acc: 0.8798\n",
            "Epoch 35/80\n",
            "78/78 [==============================] - 86s 1s/step - loss: 0.2918 - acc: 0.8734 - val_loss: 0.2558 - val_acc: 0.9014\n",
            "Epoch 36/80\n",
            "78/78 [==============================] - 83s 1s/step - loss: 0.3152 - acc: 0.8750 - val_loss: 0.2692 - val_acc: 0.8726\n",
            "Epoch 37/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3066 - acc: 0.8670 - val_loss: 0.2493 - val_acc: 0.9038\n",
            "Epoch 38/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3039 - acc: 0.8758 - val_loss: 0.2494 - val_acc: 0.9111\n",
            "Epoch 39/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3182 - acc: 0.8542 - val_loss: 0.2388 - val_acc: 0.9135\n",
            "Epoch 40/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3201 - acc: 0.8662 - val_loss: 0.2611 - val_acc: 0.9014\n",
            "Epoch 41/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.2988 - acc: 0.8782 - val_loss: 0.2452 - val_acc: 0.9038\n",
            "Epoch 42/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.2903 - acc: 0.8758 - val_loss: 0.2440 - val_acc: 0.8894\n",
            "Epoch 43/80\n",
            "78/78 [==============================] - 80s 1s/step - loss: 0.3260 - acc: 0.8630 - val_loss: 0.2461 - val_acc: 0.8990\n",
            "Epoch 44/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3039 - acc: 0.8702 - val_loss: 0.2685 - val_acc: 0.8990\n",
            "Epoch 45/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3121 - acc: 0.8782 - val_loss: 0.2509 - val_acc: 0.8918\n",
            "Epoch 46/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3251 - acc: 0.8678 - val_loss: 0.2485 - val_acc: 0.8942\n",
            "Epoch 47/80\n",
            "78/78 [==============================] - 80s 1s/step - loss: 0.3176 - acc: 0.8646 - val_loss: 0.2513 - val_acc: 0.8966\n",
            "Epoch 48/80\n",
            "78/78 [==============================] - 80s 1s/step - loss: 0.3367 - acc: 0.8494 - val_loss: 0.2835 - val_acc: 0.8846\n",
            "Epoch 49/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3426 - acc: 0.8526 - val_loss: 0.2862 - val_acc: 0.8918\n",
            "Epoch 50/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3102 - acc: 0.8654 - val_loss: 0.2902 - val_acc: 0.8894\n",
            "Epoch 51/80\n",
            "78/78 [==============================] - 80s 1s/step - loss: 0.2967 - acc: 0.8742 - val_loss: 0.2706 - val_acc: 0.8966\n",
            "Epoch 52/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3060 - acc: 0.8766 - val_loss: 0.2727 - val_acc: 0.8894\n",
            "Epoch 53/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3170 - acc: 0.8646 - val_loss: 0.2799 - val_acc: 0.8798\n",
            "Epoch 54/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3242 - acc: 0.8678 - val_loss: 0.2481 - val_acc: 0.8894\n",
            "Epoch 55/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3123 - acc: 0.8726 - val_loss: 0.2512 - val_acc: 0.8918\n",
            "Epoch 56/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3238 - acc: 0.8566 - val_loss: 0.2503 - val_acc: 0.8774\n",
            "Epoch 57/80\n",
            "78/78 [==============================] - 80s 1s/step - loss: 0.3167 - acc: 0.8646 - val_loss: 0.2449 - val_acc: 0.9014\n",
            "Epoch 58/80\n",
            "78/78 [==============================] - 80s 1s/step - loss: 0.2950 - acc: 0.8830 - val_loss: 0.2499 - val_acc: 0.8822\n",
            "Epoch 59/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.2974 - acc: 0.8734 - val_loss: 0.2906 - val_acc: 0.8822\n",
            "Epoch 60/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3166 - acc: 0.8566 - val_loss: 0.2596 - val_acc: 0.8750\n",
            "Epoch 61/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3260 - acc: 0.8622 - val_loss: 0.3510 - val_acc: 0.8486\n",
            "Epoch 62/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3548 - acc: 0.8478 - val_loss: 0.2890 - val_acc: 0.8822\n",
            "Epoch 63/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3082 - acc: 0.8678 - val_loss: 0.2548 - val_acc: 0.8894\n",
            "Epoch 64/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.2825 - acc: 0.8774 - val_loss: 0.2605 - val_acc: 0.8870\n",
            "Epoch 65/80\n",
            "78/78 [==============================] - 85s 1s/step - loss: 0.2913 - acc: 0.8790 - val_loss: 0.2471 - val_acc: 0.8990\n",
            "Epoch 66/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.2995 - acc: 0.8742 - val_loss: 0.2717 - val_acc: 0.8966\n",
            "Epoch 67/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.3124 - acc: 0.8758 - val_loss: 0.2568 - val_acc: 0.8942\n",
            "Epoch 68/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3027 - acc: 0.8718 - val_loss: 0.2525 - val_acc: 0.8966\n",
            "Epoch 69/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3103 - acc: 0.8662 - val_loss: 0.2434 - val_acc: 0.9038\n",
            "Epoch 70/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3012 - acc: 0.8702 - val_loss: 0.2532 - val_acc: 0.8942\n",
            "Epoch 71/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3253 - acc: 0.8630 - val_loss: 0.2496 - val_acc: 0.8942\n",
            "Epoch 72/80\n",
            "78/78 [==============================] - 81s 1s/step - loss: 0.2803 - acc: 0.8742 - val_loss: 0.2551 - val_acc: 0.8966\n",
            "Epoch 73/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3082 - acc: 0.8678 - val_loss: 0.2492 - val_acc: 0.8918\n",
            "Epoch 74/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3164 - acc: 0.8694 - val_loss: 0.2696 - val_acc: 0.8846\n",
            "Epoch 75/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3018 - acc: 0.8782 - val_loss: 0.2522 - val_acc: 0.9014\n",
            "Epoch 76/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3098 - acc: 0.8598 - val_loss: 0.2524 - val_acc: 0.8942\n",
            "Epoch 77/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.3069 - acc: 0.8718 - val_loss: 0.2575 - val_acc: 0.8990\n",
            "Epoch 78/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.2893 - acc: 0.8806 - val_loss: 0.2593 - val_acc: 0.8798\n",
            "Epoch 79/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.2964 - acc: 0.8678 - val_loss: 0.2771 - val_acc: 0.8798\n",
            "Epoch 80/80\n",
            "78/78 [==============================] - 82s 1s/step - loss: 0.2794 - acc: 0.8862 - val_loss: 0.2507 - val_acc: 0.9014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G90Sk0V-tg1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4a32ff-77bd-42f5-d06a-75d0ac7dbd18"
      },
      "source": [
        "y_test_100x = test_generator_100x.classes\n",
        "y_pred_100x = model_100x.predict(test_generator_100x, verbose = 1)\n",
        "y_pred_100x = np.argmax(y_pred_100x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_100x, y_pred_100x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_100x, y_pred_100x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_100x, y_pred_100x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_100x, y_pred_100x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 116s 4s/step\n",
            "The Accuracy on the testing data : 87.29%\n",
            "The F1 Score on the testing data : 90.35%\n",
            "The Precision on the testing data : 92.88%\n",
            "The Recall on the testing data : 87.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkc8HDvAtg4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b02ab03-f647-41da-b20d-484162d19c62"
      },
      "source": [
        "tn_100x, fp_100x, fn_100x, tp_100x = confusion_matrix(y_test_100x, y_pred_100x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_100x)\n",
        "print('True Negitive : ',tn_100x)\n",
        "print('False Positive : ',fp_100x)\n",
        "print('False Negitive : ',fn_100x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  248\n",
            "True Negitive :  116\n",
            "False Positive :  19\n",
            "False Negitive :  34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afZjc5Xx5A-6",
        "outputId": "4cfb6d75-51af-46fc-c4c9-eb1931953de2"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (248 / (248 + 34))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (116 / (116 + 19))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  87.94%\n",
            "Specificity :  85.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09C41A8ptxIK"
      },
      "source": [
        "### 200x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5-PP_2Ytg6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b23fc08-cf38-41c6-9efc-3ec4e451c543"
      },
      "source": [
        "train_generator_200x = datagen.flow_from_directory( train_200x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_200x = datagen_test.flow_from_directory( valid_200x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_200x = datagen_test.flow_from_directory( test_200x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1207 images belonging to 2 classes.\n",
            "Found 403 images belonging to 2 classes.\n",
            "Found 403 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQssv334tg8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaceb9d5-64ce-4dca-99dc-53352442c7d9"
      },
      "source": [
        "mob_200x = MobileNetV2(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_200x = Sequential()\n",
        "model_200x.add(mob_200x)\n",
        "model_200x.add(GlobalAveragePooling2D())\n",
        "model_200x.add(Dropout(0.2))\n",
        "model_200x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "mob_200x.trainable = False\n",
        "\n",
        "model_200x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "\n",
        "hist_200x = model_200x.fit(train_generator_200x, validation_data = valid_generator_200x, epochs = n_epochs, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "76/76 [==============================] - 438s 6s/step - loss: 0.5958 - acc: 0.7167 - val_loss: 0.4456 - val_acc: 0.7965\n",
            "Epoch 2/80\n",
            "76/76 [==============================] - 81s 1s/step - loss: 0.4595 - acc: 0.7829 - val_loss: 0.4338 - val_acc: 0.7990\n",
            "Epoch 3/80\n",
            "76/76 [==============================] - 81s 1s/step - loss: 0.4041 - acc: 0.8036 - val_loss: 0.3883 - val_acc: 0.8362\n",
            "Epoch 4/80\n",
            "76/76 [==============================] - 81s 1s/step - loss: 0.3789 - acc: 0.8302 - val_loss: 0.3776 - val_acc: 0.8313\n",
            "Epoch 5/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3788 - acc: 0.8293 - val_loss: 0.3665 - val_acc: 0.8387\n",
            "Epoch 6/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3599 - acc: 0.8343 - val_loss: 0.3679 - val_acc: 0.8313\n",
            "Epoch 7/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3587 - acc: 0.8384 - val_loss: 0.3817 - val_acc: 0.8164\n",
            "Epoch 8/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3408 - acc: 0.8517 - val_loss: 0.3318 - val_acc: 0.8710\n",
            "Epoch 9/80\n",
            "76/76 [==============================] - 83s 1s/step - loss: 0.3608 - acc: 0.8459 - val_loss: 0.3281 - val_acc: 0.8586\n",
            "Epoch 10/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3645 - acc: 0.8335 - val_loss: 0.3261 - val_acc: 0.8660\n",
            "Epoch 11/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3192 - acc: 0.8542 - val_loss: 0.3107 - val_acc: 0.8710\n",
            "Epoch 12/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3329 - acc: 0.8484 - val_loss: 0.3372 - val_acc: 0.8586\n",
            "Epoch 13/80\n",
            "76/76 [==============================] - 81s 1s/step - loss: 0.3131 - acc: 0.8625 - val_loss: 0.3171 - val_acc: 0.8710\n",
            "Epoch 14/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3286 - acc: 0.8534 - val_loss: 0.3686 - val_acc: 0.8263\n",
            "Epoch 15/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3021 - acc: 0.8658 - val_loss: 0.3522 - val_acc: 0.8412\n",
            "Epoch 16/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3165 - acc: 0.8691 - val_loss: 0.3166 - val_acc: 0.8610\n",
            "Epoch 17/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2950 - acc: 0.8749 - val_loss: 0.3645 - val_acc: 0.8313\n",
            "Epoch 18/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3019 - acc: 0.8650 - val_loss: 0.2895 - val_acc: 0.8759\n",
            "Epoch 19/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2848 - acc: 0.8790 - val_loss: 0.3206 - val_acc: 0.8635\n",
            "Epoch 20/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2932 - acc: 0.8650 - val_loss: 0.3138 - val_acc: 0.8486\n",
            "Epoch 21/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3186 - acc: 0.8708 - val_loss: 0.2884 - val_acc: 0.8784\n",
            "Epoch 22/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2938 - acc: 0.8658 - val_loss: 0.2786 - val_acc: 0.8859\n",
            "Epoch 23/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2987 - acc: 0.8674 - val_loss: 0.3260 - val_acc: 0.8437\n",
            "Epoch 24/80\n",
            "76/76 [==============================] - 83s 1s/step - loss: 0.2918 - acc: 0.8658 - val_loss: 0.3077 - val_acc: 0.8536\n",
            "Epoch 25/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2813 - acc: 0.8782 - val_loss: 0.2779 - val_acc: 0.8660\n",
            "Epoch 26/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2840 - acc: 0.8832 - val_loss: 0.2898 - val_acc: 0.8635\n",
            "Epoch 27/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2797 - acc: 0.8708 - val_loss: 0.3888 - val_acc: 0.8040\n",
            "Epoch 28/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2708 - acc: 0.8848 - val_loss: 0.3109 - val_acc: 0.8660\n",
            "Epoch 29/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3338 - acc: 0.8476 - val_loss: 0.2782 - val_acc: 0.8883\n",
            "Epoch 30/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3005 - acc: 0.8782 - val_loss: 0.2864 - val_acc: 0.8834\n",
            "Epoch 31/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2851 - acc: 0.8799 - val_loss: 0.3117 - val_acc: 0.8759\n",
            "Epoch 32/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2831 - acc: 0.8840 - val_loss: 0.2847 - val_acc: 0.8784\n",
            "Epoch 33/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2876 - acc: 0.8757 - val_loss: 0.2988 - val_acc: 0.8536\n",
            "Epoch 34/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2689 - acc: 0.8774 - val_loss: 0.3335 - val_acc: 0.8462\n",
            "Epoch 35/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2860 - acc: 0.8683 - val_loss: 0.3161 - val_acc: 0.8660\n",
            "Epoch 36/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3206 - acc: 0.8658 - val_loss: 0.3466 - val_acc: 0.8387\n",
            "Epoch 37/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2985 - acc: 0.8840 - val_loss: 0.3061 - val_acc: 0.8511\n",
            "Epoch 38/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2742 - acc: 0.8848 - val_loss: 0.3037 - val_acc: 0.8685\n",
            "Epoch 39/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3052 - acc: 0.8699 - val_loss: 0.3330 - val_acc: 0.8561\n",
            "Epoch 40/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2688 - acc: 0.8807 - val_loss: 0.2882 - val_acc: 0.8834\n",
            "Epoch 41/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2788 - acc: 0.8807 - val_loss: 0.2894 - val_acc: 0.8685\n",
            "Epoch 42/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2684 - acc: 0.8923 - val_loss: 0.2783 - val_acc: 0.8809\n",
            "Epoch 43/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2812 - acc: 0.8790 - val_loss: 0.2820 - val_acc: 0.8958\n",
            "Epoch 44/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3016 - acc: 0.8724 - val_loss: 0.3256 - val_acc: 0.8586\n",
            "Epoch 45/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2801 - acc: 0.8774 - val_loss: 0.3007 - val_acc: 0.8809\n",
            "Epoch 46/80\n",
            "76/76 [==============================] - 84s 1s/step - loss: 0.2822 - acc: 0.8683 - val_loss: 0.3050 - val_acc: 0.8685\n",
            "Epoch 47/80\n",
            "76/76 [==============================] - 81s 1s/step - loss: 0.3089 - acc: 0.8716 - val_loss: 0.3014 - val_acc: 0.8784\n",
            "Epoch 48/80\n",
            "76/76 [==============================] - 81s 1s/step - loss: 0.2968 - acc: 0.8749 - val_loss: 0.2962 - val_acc: 0.8685\n",
            "Epoch 49/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2955 - acc: 0.8600 - val_loss: 0.2743 - val_acc: 0.8958\n",
            "Epoch 50/80\n",
            "76/76 [==============================] - 81s 1s/step - loss: 0.2688 - acc: 0.8848 - val_loss: 0.2813 - val_acc: 0.8933\n",
            "Epoch 51/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2929 - acc: 0.8691 - val_loss: 0.2762 - val_acc: 0.8908\n",
            "Epoch 52/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2939 - acc: 0.8749 - val_loss: 0.2971 - val_acc: 0.8635\n",
            "Epoch 53/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.3098 - acc: 0.8575 - val_loss: 0.2940 - val_acc: 0.8759\n",
            "Epoch 54/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2725 - acc: 0.8857 - val_loss: 0.3421 - val_acc: 0.8536\n",
            "Epoch 55/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2967 - acc: 0.8749 - val_loss: 0.2831 - val_acc: 0.8834\n",
            "Epoch 56/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2790 - acc: 0.8865 - val_loss: 0.2943 - val_acc: 0.8784\n",
            "Epoch 57/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2696 - acc: 0.8741 - val_loss: 0.2844 - val_acc: 0.8958\n",
            "Epoch 58/80\n",
            "76/76 [==============================] - 80s 1s/step - loss: 0.2762 - acc: 0.8857 - val_loss: 0.3456 - val_acc: 0.8511\n",
            "Epoch 59/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3002 - acc: 0.8716 - val_loss: 0.3100 - val_acc: 0.8660\n",
            "Epoch 60/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2889 - acc: 0.8782 - val_loss: 0.3020 - val_acc: 0.8784\n",
            "Epoch 61/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2602 - acc: 0.8857 - val_loss: 0.3374 - val_acc: 0.8586\n",
            "Epoch 62/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3062 - acc: 0.8633 - val_loss: 0.3774 - val_acc: 0.8263\n",
            "Epoch 63/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.2813 - acc: 0.8766 - val_loss: 0.2756 - val_acc: 0.8883\n",
            "Epoch 64/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2647 - acc: 0.8832 - val_loss: 0.3098 - val_acc: 0.8685\n",
            "Epoch 65/80\n",
            "76/76 [==============================] - 79s 1s/step - loss: 0.3213 - acc: 0.8658 - val_loss: 0.2718 - val_acc: 0.8734\n",
            "Epoch 66/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2657 - acc: 0.8766 - val_loss: 0.3181 - val_acc: 0.8486\n",
            "Epoch 67/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.3315 - acc: 0.8558 - val_loss: 0.3256 - val_acc: 0.8536\n",
            "Epoch 68/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2766 - acc: 0.8824 - val_loss: 0.3912 - val_acc: 0.8238\n",
            "Epoch 69/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.3074 - acc: 0.8658 - val_loss: 0.3193 - val_acc: 0.8561\n",
            "Epoch 70/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2687 - acc: 0.8890 - val_loss: 0.2835 - val_acc: 0.8933\n",
            "Epoch 71/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.3085 - acc: 0.8650 - val_loss: 0.2840 - val_acc: 0.8859\n",
            "Epoch 72/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.3086 - acc: 0.8799 - val_loss: 0.2612 - val_acc: 0.9032\n",
            "Epoch 73/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2496 - acc: 0.8940 - val_loss: 0.3123 - val_acc: 0.8660\n",
            "Epoch 74/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.3029 - acc: 0.8683 - val_loss: 0.2818 - val_acc: 0.8809\n",
            "Epoch 75/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2756 - acc: 0.8898 - val_loss: 0.3436 - val_acc: 0.8313\n",
            "Epoch 76/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2828 - acc: 0.8790 - val_loss: 0.2845 - val_acc: 0.8784\n",
            "Epoch 77/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2649 - acc: 0.8882 - val_loss: 0.3279 - val_acc: 0.8511\n",
            "Epoch 78/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2969 - acc: 0.8732 - val_loss: 0.2904 - val_acc: 0.8784\n",
            "Epoch 79/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2846 - acc: 0.8807 - val_loss: 0.3095 - val_acc: 0.8784\n",
            "Epoch 80/80\n",
            "76/76 [==============================] - 78s 1s/step - loss: 0.2606 - acc: 0.8923 - val_loss: 0.2995 - val_acc: 0.8784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTjS18lt-5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f9bcb6-120f-4310-bae9-1a6affdc4bce"
      },
      "source": [
        "y_test_200x = test_generator_200x.classes\n",
        "y_pred_200x = model_200x.predict(test_generator_200x, verbose = 1)\n",
        "y_pred_200x = np.argmax(y_pred_200x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_200x, y_pred_200x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_200x, y_pred_200x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_200x, y_pred_200x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_200x, y_pred_200x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 107s 4s/step\n",
            "The Accuracy on the testing data : 85.86%\n",
            "The F1 Score on the testing data : 89.73%\n",
            "The Precision on the testing data : 90.22%\n",
            "The Recall on the testing data : 89.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iorF1356t-86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad05390-d91f-4ea2-9ca3-ab0c0b2ac011"
      },
      "source": [
        "tn_200x, fp_200x, fn_200x, tp_200x = confusion_matrix(y_test_200x, y_pred_200x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_200x)\n",
        "print('True Negitive : ',tn_200x)\n",
        "print('False Positive : ',fp_200x)\n",
        "print('False Negitive : ',fn_200x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  249\n",
            "True Negitive :  97\n",
            "False Positive :  27\n",
            "False Negitive :  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUtf06325C6s",
        "outputId": "e8700d39-bb58-4b58-a9e2-633a171c8557"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (249 / (249 + 30))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (97 / (97 + 27))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  89.25%\n",
            "Specificity :  78.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWtWA2peuFlH"
      },
      "source": [
        "### 400x Magnification Factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me6XQ6ust_Fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e388255-2f25-4c80-bdd9-3999117e8272"
      },
      "source": [
        "train_generator_400x = datagen.flow_from_directory( train_400x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "valid_generator_400x = datagen_test.flow_from_directory( valid_400x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = True)\n",
        "test_generator_400x = datagen_test.flow_from_directory( test_400x_path, target_size = (height, width), batch_size = batch_size, class_mode = 'categorical', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1092 images belonging to 2 classes.\n",
            "Found 364 images belonging to 2 classes.\n",
            "Found 364 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5tDTX63t_Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1528a9aa-5d55-4a39-cac6-57fcd859d0e1"
      },
      "source": [
        "mob_400x = MobileNetV2(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n",
        "model_400x = Sequential()\n",
        "model_400x.add(mob_400x)\n",
        "model_400x.add(GlobalAveragePooling2D())\n",
        "model_400x.add(Dropout(0.2))\n",
        "model_400x.add(Dense(n_classes, activation = 'softmax'))\n",
        "\n",
        "mob_400x.trainable = False\n",
        "\n",
        "model_400x.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=lr), metrics = ['acc'])\n",
        "\n",
        "hist_400x = model_400x.fit(train_generator_400x, validation_data = valid_generator_400x, epochs = n_epochs, verbose = 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "69/69 [==============================] - 428s 6s/step - loss: 0.6475 - acc: 0.6914 - val_loss: 0.4826 - val_acc: 0.7582\n",
            "Epoch 2/80\n",
            "69/69 [==============================] - 74s 1s/step - loss: 0.5089 - acc: 0.7592 - val_loss: 0.4783 - val_acc: 0.7637\n",
            "Epoch 3/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.4828 - acc: 0.7720 - val_loss: 0.4653 - val_acc: 0.7665\n",
            "Epoch 4/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.4451 - acc: 0.7958 - val_loss: 0.4391 - val_acc: 0.7830\n",
            "Epoch 5/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.4250 - acc: 0.8086 - val_loss: 0.4290 - val_acc: 0.7995\n",
            "Epoch 6/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.4107 - acc: 0.8187 - val_loss: 0.4306 - val_acc: 0.7912\n",
            "Epoch 7/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.3977 - acc: 0.8361 - val_loss: 0.4453 - val_acc: 0.8159\n",
            "Epoch 8/80\n",
            "69/69 [==============================] - 76s 1s/step - loss: 0.3874 - acc: 0.8352 - val_loss: 0.4213 - val_acc: 0.8049\n",
            "Epoch 9/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3558 - acc: 0.8434 - val_loss: 0.4207 - val_acc: 0.7912\n",
            "Epoch 10/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3767 - acc: 0.8342 - val_loss: 0.4423 - val_acc: 0.7967\n",
            "Epoch 11/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3535 - acc: 0.8388 - val_loss: 0.4045 - val_acc: 0.8242\n",
            "Epoch 12/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3712 - acc: 0.8352 - val_loss: 0.4064 - val_acc: 0.8187\n",
            "Epoch 13/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3594 - acc: 0.8342 - val_loss: 0.3970 - val_acc: 0.8104\n",
            "Epoch 14/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3355 - acc: 0.8535 - val_loss: 0.3953 - val_acc: 0.8242\n",
            "Epoch 15/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3373 - acc: 0.8507 - val_loss: 0.3955 - val_acc: 0.8297\n",
            "Epoch 16/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3554 - acc: 0.8452 - val_loss: 0.3902 - val_acc: 0.8187\n",
            "Epoch 17/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3306 - acc: 0.8626 - val_loss: 0.4034 - val_acc: 0.8159\n",
            "Epoch 18/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3529 - acc: 0.8425 - val_loss: 0.3930 - val_acc: 0.8324\n",
            "Epoch 19/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3161 - acc: 0.8645 - val_loss: 0.3782 - val_acc: 0.8269\n",
            "Epoch 20/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3386 - acc: 0.8562 - val_loss: 0.3807 - val_acc: 0.8269\n",
            "Epoch 21/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.3319 - acc: 0.8526 - val_loss: 0.3914 - val_acc: 0.8352\n",
            "Epoch 22/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3688 - acc: 0.8471 - val_loss: 0.4231 - val_acc: 0.8022\n",
            "Epoch 23/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3327 - acc: 0.8507 - val_loss: 0.3711 - val_acc: 0.8407\n",
            "Epoch 24/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3229 - acc: 0.8516 - val_loss: 0.3741 - val_acc: 0.8462\n",
            "Epoch 25/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3572 - acc: 0.8571 - val_loss: 0.3711 - val_acc: 0.8407\n",
            "Epoch 26/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3433 - acc: 0.8443 - val_loss: 0.4504 - val_acc: 0.7857\n",
            "Epoch 27/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3009 - acc: 0.8810 - val_loss: 0.3560 - val_acc: 0.8297\n",
            "Epoch 28/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3291 - acc: 0.8608 - val_loss: 0.3674 - val_acc: 0.8324\n",
            "Epoch 29/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3477 - acc: 0.8425 - val_loss: 0.3808 - val_acc: 0.8434\n",
            "Epoch 30/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3348 - acc: 0.8581 - val_loss: 0.3773 - val_acc: 0.8324\n",
            "Epoch 31/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3039 - acc: 0.8681 - val_loss: 0.3811 - val_acc: 0.8352\n",
            "Epoch 32/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3428 - acc: 0.8571 - val_loss: 0.3634 - val_acc: 0.8324\n",
            "Epoch 33/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3121 - acc: 0.8654 - val_loss: 0.3674 - val_acc: 0.8462\n",
            "Epoch 34/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3095 - acc: 0.8773 - val_loss: 0.3820 - val_acc: 0.8434\n",
            "Epoch 35/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3324 - acc: 0.8608 - val_loss: 0.5165 - val_acc: 0.7665\n",
            "Epoch 36/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3247 - acc: 0.8654 - val_loss: 0.4423 - val_acc: 0.7995\n",
            "Epoch 37/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.3342 - acc: 0.8645 - val_loss: 0.3834 - val_acc: 0.8407\n",
            "Epoch 38/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.3100 - acc: 0.8681 - val_loss: 0.3914 - val_acc: 0.8434\n",
            "Epoch 39/80\n",
            "69/69 [==============================] - 74s 1s/step - loss: 0.3039 - acc: 0.8599 - val_loss: 0.3877 - val_acc: 0.8352\n",
            "Epoch 40/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3308 - acc: 0.8571 - val_loss: 0.3852 - val_acc: 0.8434\n",
            "Epoch 41/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3183 - acc: 0.8544 - val_loss: 0.3906 - val_acc: 0.8379\n",
            "Epoch 42/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3187 - acc: 0.8581 - val_loss: 0.4249 - val_acc: 0.8049\n",
            "Epoch 43/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2936 - acc: 0.8764 - val_loss: 0.3830 - val_acc: 0.8269\n",
            "Epoch 44/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3266 - acc: 0.8553 - val_loss: 0.3696 - val_acc: 0.8407\n",
            "Epoch 45/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2995 - acc: 0.8645 - val_loss: 0.4076 - val_acc: 0.8242\n",
            "Epoch 46/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2823 - acc: 0.8800 - val_loss: 0.3922 - val_acc: 0.8324\n",
            "Epoch 47/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3260 - acc: 0.8581 - val_loss: 0.3771 - val_acc: 0.8352\n",
            "Epoch 48/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.3264 - acc: 0.8663 - val_loss: 0.3823 - val_acc: 0.8324\n",
            "Epoch 49/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3244 - acc: 0.8645 - val_loss: 0.3773 - val_acc: 0.8407\n",
            "Epoch 50/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3270 - acc: 0.8571 - val_loss: 0.3821 - val_acc: 0.8297\n",
            "Epoch 51/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2888 - acc: 0.8846 - val_loss: 0.3763 - val_acc: 0.8324\n",
            "Epoch 52/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.3226 - acc: 0.8581 - val_loss: 0.3733 - val_acc: 0.8379\n",
            "Epoch 53/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3012 - acc: 0.8645 - val_loss: 0.3740 - val_acc: 0.8352\n",
            "Epoch 54/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2900 - acc: 0.8626 - val_loss: 0.4133 - val_acc: 0.8104\n",
            "Epoch 55/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3035 - acc: 0.8663 - val_loss: 0.4192 - val_acc: 0.8104\n",
            "Epoch 56/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2933 - acc: 0.8709 - val_loss: 0.3942 - val_acc: 0.8352\n",
            "Epoch 57/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2927 - acc: 0.8791 - val_loss: 0.3741 - val_acc: 0.8407\n",
            "Epoch 58/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3088 - acc: 0.8736 - val_loss: 0.3740 - val_acc: 0.8434\n",
            "Epoch 59/80\n",
            "69/69 [==============================] - 75s 1s/step - loss: 0.3074 - acc: 0.8672 - val_loss: 0.3699 - val_acc: 0.8352\n",
            "Epoch 60/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2905 - acc: 0.8791 - val_loss: 0.3731 - val_acc: 0.8407\n",
            "Epoch 61/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2800 - acc: 0.8736 - val_loss: 0.3750 - val_acc: 0.8516\n",
            "Epoch 62/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3141 - acc: 0.8755 - val_loss: 0.3759 - val_acc: 0.8462\n",
            "Epoch 63/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3038 - acc: 0.8599 - val_loss: 0.3735 - val_acc: 0.8434\n",
            "Epoch 64/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3009 - acc: 0.8681 - val_loss: 0.3853 - val_acc: 0.8324\n",
            "Epoch 65/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3361 - acc: 0.8544 - val_loss: 0.3890 - val_acc: 0.8352\n",
            "Epoch 66/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3211 - acc: 0.8617 - val_loss: 0.3944 - val_acc: 0.8242\n",
            "Epoch 67/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3092 - acc: 0.8672 - val_loss: 0.4484 - val_acc: 0.8104\n",
            "Epoch 68/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3158 - acc: 0.8544 - val_loss: 0.3899 - val_acc: 0.8352\n",
            "Epoch 69/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2703 - acc: 0.8864 - val_loss: 0.4881 - val_acc: 0.7967\n",
            "Epoch 70/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3356 - acc: 0.8526 - val_loss: 0.3791 - val_acc: 0.8407\n",
            "Epoch 71/80\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.3332 - acc: 0.8590 - val_loss: 0.3965 - val_acc: 0.8462\n",
            "Epoch 72/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3153 - acc: 0.8681 - val_loss: 0.3809 - val_acc: 0.8407\n",
            "Epoch 73/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3151 - acc: 0.8736 - val_loss: 0.3848 - val_acc: 0.8462\n",
            "Epoch 74/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2868 - acc: 0.8782 - val_loss: 0.4024 - val_acc: 0.8159\n",
            "Epoch 75/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3026 - acc: 0.8690 - val_loss: 0.4128 - val_acc: 0.8214\n",
            "Epoch 76/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2981 - acc: 0.8663 - val_loss: 0.4178 - val_acc: 0.8352\n",
            "Epoch 77/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2970 - acc: 0.8654 - val_loss: 0.4021 - val_acc: 0.8407\n",
            "Epoch 78/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.3078 - acc: 0.8663 - val_loss: 0.4005 - val_acc: 0.8324\n",
            "Epoch 79/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2937 - acc: 0.8764 - val_loss: 0.3848 - val_acc: 0.8434\n",
            "Epoch 80/80\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.2966 - acc: 0.8727 - val_loss: 0.3921 - val_acc: 0.8352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XobF5uKcuU3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6537389f-8f3a-47a0-ce15-1d72dd5ea5a9"
      },
      "source": [
        "y_test_400x = test_generator_400x.classes\n",
        "y_pred_400x = model_400x.predict(test_generator_400x, verbose = 1)\n",
        "y_pred_400x = np.argmax(y_pred_400x, axis = 1)\n",
        "\n",
        "print(\"The Accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test_400x, y_pred_400x)))\n",
        "print(\"The F1 Score on the testing data : {:.2f}%\".format(100 * f1_score(y_test_400x, y_pred_400x)))\n",
        "print(\"The Precision on the testing data : {:.2f}%\".format(100 * precision_score(y_test_400x, y_pred_400x)))\n",
        "print(\"The Recall on the testing data : {:.2f}%\".format(100 * recall_score(y_test_400x, y_pred_400x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 98s 4s/step\n",
            "The Accuracy on the testing data : 84.07%\n",
            "The F1 Score on the testing data : 87.82%\n",
            "The Precision on the testing data : 87.82%\n",
            "The Recall on the testing data : 87.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icn6qS6uXdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07ddf6a-a372-4528-c949-019c3ee17577"
      },
      "source": [
        "tn_400x, fp_400x, fn_400x, tp_400x = confusion_matrix(y_test_400x, y_pred_400x).ravel()\n",
        "\n",
        "print('True Positive : ',tp_400x)\n",
        "print('True Negitive : ',tn_400x)\n",
        "print('False Positive : ',fp_400x)\n",
        "print('False Negitive : ',fn_400x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive :  209\n",
            "True Negitive :  97\n",
            "False Positive :  29\n",
            "False Negitive :  29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9HE9mw45EVS",
        "outputId": "e617b0d2-6472-48c6-b9da-fd6c45daef27"
      },
      "source": [
        "print('Sensitivity :  {:.2f}%'.format(100 * (209 / (209 + 29))))\n",
        "print('Specificity :  {:.2f}%'.format(100 * (97 / (97 + 29))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  87.82%\n",
            "Specificity :  76.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTh2scscqP8P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}